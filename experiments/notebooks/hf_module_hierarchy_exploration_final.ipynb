{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Static Hierarchy Building**: Fast analysis of model structure using class names\n",
    "2. **Tracing-Based Hierarchy Building**: Accurate execution-based hierarchy capture\n",
    "3. **Production TracingHierarchyBuilder**: The actual implementation used in HTP exporter\n",
    "4. **Pretty Display**: Beautiful visualization using Rich library with proper styling\n",
    "\n",
    "The key insight is that the production TracingHierarchyBuilder provides the most accurate hierarchy information by tracing actual model execution, and the Rich library helps create beautiful, readable output similar to the HTP exporter's display."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Count Analysis\n",
    "\n",
    "Let's analyze how many ONNX nodes would be tagged with each hierarchy tag, similar to the HTP exporter output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretty Display with Rich Library\n",
    "\n",
    "Let's display the hierarchy data in a beautiful format using Rich library, similar to how the HTP exporter displays it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Actual TracingHierarchyBuilder from modelexport.core\n",
    "\n",
    "Now let's use the actual implementation from our codebase and display the results in a pretty format. This section demonstrates how to use the production TracingHierarchyBuilder that is used in the HTP exporter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Actual TracingHierarchyBuilder from modelexport.core\n",
    "\n",
    "Now let's use the actual implementation from our codebase and display the results in a pretty format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading prajjwal1/bert-tiny...\n",
      "Model type: <class 'transformers.models.bert.modeling_bert.BertModel'>\n",
      "Model class: BertModel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model type: <class 'transformers.models.bert.modeling_bert.BertModel'>\n",
      "Model class: BertModel\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Configuration - set your model here\n",
    "MODEL_NAME = \"prajjwal1/bert-tiny\"  # Change this to test different models\n",
    "\n",
    "# Load the model\n",
    "print(f\"Loading {MODEL_NAME}...\")\n",
    "model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "print(f\"Model type: {type(model)}\")\n",
    "print(f\"Model class: {model.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# HuggingFace Module Hierarchy Exploration Notebook\n\nThis notebook explores different approaches to building HuggingFace module hierarchies and demonstrates the TracingHierarchyBuilder used in the HTP exporter.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_hf_class(module):\n",
    "    \"\"\"Check if a module is a HuggingFace class\"\"\"\n",
    "    module_path = module.__class__.__module__\n",
    "    return module_path.startswith('transformers')\n",
    "\n",
    "def build_hf_hierarchy_mapping(model):\n",
    "    \"\"\"Recursively build HF module hierarchy mapping\"\"\"\n",
    "    hierarchy_mapping = {}\n",
    "    \n",
    "    def recursive_build(module, current_tag, module_name, parent_children_names=None):\n",
    "        \"\"\"Recursively build hierarchy for a module\"\"\"\n",
    "        \n",
    "        # If this is an HF class, update the tag\n",
    "        if is_hf_class(module):\n",
    "            class_name = module.__class__.__name__\n",
    "            \n",
    "            # Add index if this is a repeated class among siblings\n",
    "            if parent_children_names and module_name:\n",
    "                module_basename = module_name.split('.')[-1]\n",
    "                # Count how many siblings have the same class name\n",
    "                same_class_siblings = []\n",
    "                for sibling_name in parent_children_names:\n",
    "                    if sibling_name == module_basename:\n",
    "                        same_class_siblings.append(sibling_name)\n",
    "                \n",
    "                # If there are multiple siblings with same class, add index\n",
    "                if len(same_class_siblings) > 1 or module_basename.isdigit():\n",
    "                    # Extract index from module name (e.g., \"0\" from \"layer.0\")\n",
    "                    if module_basename.isdigit():\n",
    "                        index = module_basename\n",
    "                        current_tag = f\"{current_tag}/{class_name}.{index}\"\n",
    "                    else:\n",
    "                        current_tag = f\"{current_tag}/{class_name}\"\n",
    "                else:\n",
    "                    current_tag = f\"{current_tag}/{class_name}\"\n",
    "            else:\n",
    "                current_tag = f\"{current_tag}/{class_name}\"\n",
    "        \n",
    "        # Map this module to its hierarchy tag\n",
    "        if module_name:  # Skip root module\n",
    "            hierarchy_mapping[module_name] = current_tag\n",
    "        \n",
    "        # Get children names for indexing\n",
    "        children_names = [name for name, _ in module.named_children()]\n",
    "        \n",
    "        # Recursively process children\n",
    "        for child_name, child_module in module.named_children():\n",
    "            child_full_name = f\"{module_name}.{child_name}\" if module_name else child_name\n",
    "            recursive_build(child_module, current_tag, child_full_name, children_names)\n",
    "    \n",
    "    # Start with root model - use simple class name without duplication\n",
    "    root_class = model.__class__.__name__\n",
    "    initial_tag = f\"/{root_class}\" if is_hf_class(model) else \"\"\n",
    "    \n",
    "    # Skip the root model itself and start with its children to avoid duplication\n",
    "    for child_name, child_module in model.named_children():\n",
    "        recursive_build(child_module, initial_tag, child_name, [name for name, _ in model.named_children()])\n",
    "    \n",
    "    return hierarchy_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building static HF hierarchy mapping...\n",
      "\n",
      "Found 47 module mappings:\n",
      "======================================================================\n",
      "embeddings                               -> /BertModel/BertEmbeddings\n",
      "embeddings.LayerNorm                     -> /BertModel/BertEmbeddings\n",
      "embeddings.dropout                       -> /BertModel/BertEmbeddings\n",
      "embeddings.position_embeddings           -> /BertModel/BertEmbeddings\n",
      "embeddings.token_type_embeddings         -> /BertModel/BertEmbeddings\n",
      "embeddings.word_embeddings               -> /BertModel/BertEmbeddings\n",
      "encoder                                  -> /BertModel/BertEncoder\n",
      "encoder.layer                            -> /BertModel/BertEncoder\n",
      "encoder.layer.0                          -> /BertModel/BertEncoder/BertLayer.0\n",
      "encoder.layer.0.attention                -> /BertModel/BertEncoder/BertLayer.0/BertAttention\n",
      "encoder.layer.0.attention.output         -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSelfOutput\n",
      "encoder.layer.0.attention.output.LayerNorm -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSelfOutput\n",
      "encoder.layer.0.attention.output.dense   -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSelfOutput\n",
      "encoder.layer.0.attention.output.dropout -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSelfOutput\n",
      "encoder.layer.0.attention.self           -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention\n",
      "encoder.layer.0.attention.self.dropout   -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention\n",
      "encoder.layer.0.attention.self.key       -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention\n",
      "encoder.layer.0.attention.self.query     -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention\n",
      "encoder.layer.0.attention.self.value     -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention\n",
      "encoder.layer.0.intermediate             -> /BertModel/BertEncoder/BertLayer.0/BertIntermediate\n",
      "encoder.layer.0.intermediate.dense       -> /BertModel/BertEncoder/BertLayer.0/BertIntermediate\n",
      "encoder.layer.0.intermediate.intermediate_act_fn -> /BertModel/BertEncoder/BertLayer.0/BertIntermediate/GELUActivation\n",
      "encoder.layer.0.output                   -> /BertModel/BertEncoder/BertLayer.0/BertOutput\n",
      "encoder.layer.0.output.LayerNorm         -> /BertModel/BertEncoder/BertLayer.0/BertOutput\n",
      "encoder.layer.0.output.dense             -> /BertModel/BertEncoder/BertLayer.0/BertOutput\n",
      "encoder.layer.0.output.dropout           -> /BertModel/BertEncoder/BertLayer.0/BertOutput\n",
      "encoder.layer.1                          -> /BertModel/BertEncoder/BertLayer.1\n",
      "encoder.layer.1.attention                -> /BertModel/BertEncoder/BertLayer.1/BertAttention\n",
      "encoder.layer.1.attention.output         -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSelfOutput\n",
      "encoder.layer.1.attention.output.LayerNorm -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSelfOutput\n",
      "encoder.layer.1.attention.output.dense   -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSelfOutput\n",
      "encoder.layer.1.attention.output.dropout -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSelfOutput\n",
      "encoder.layer.1.attention.self           -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention\n",
      "encoder.layer.1.attention.self.dropout   -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention\n",
      "encoder.layer.1.attention.self.key       -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention\n",
      "encoder.layer.1.attention.self.query     -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention\n",
      "encoder.layer.1.attention.self.value     -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention\n",
      "encoder.layer.1.intermediate             -> /BertModel/BertEncoder/BertLayer.1/BertIntermediate\n",
      "encoder.layer.1.intermediate.dense       -> /BertModel/BertEncoder/BertLayer.1/BertIntermediate\n",
      "encoder.layer.1.intermediate.intermediate_act_fn -> /BertModel/BertEncoder/BertLayer.1/BertIntermediate/GELUActivation\n",
      "encoder.layer.1.output                   -> /BertModel/BertEncoder/BertLayer.1/BertOutput\n",
      "encoder.layer.1.output.LayerNorm         -> /BertModel/BertEncoder/BertLayer.1/BertOutput\n",
      "encoder.layer.1.output.dense             -> /BertModel/BertEncoder/BertLayer.1/BertOutput\n",
      "encoder.layer.1.output.dropout           -> /BertModel/BertEncoder/BertLayer.1/BertOutput\n",
      "pooler                                   -> /BertModel/BertPooler\n",
      "pooler.activation                        -> /BertModel/BertPooler\n",
      "pooler.dense                             -> /BertModel/BertPooler\n"
     ]
    }
   ],
   "source": [
    "# Build the static mapping\n",
    "print(\"Building static HF hierarchy mapping...\")\n",
    "static_hierarchy_mapping = build_hf_hierarchy_mapping(model)\n",
    "\n",
    "print(f\"\\nFound {len(static_hierarchy_mapping)} module mappings:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for module_name, hierarchy_tag in sorted(static_hierarchy_mapping.items()):\n",
    "    print(f\"{module_name:40} -> {hierarchy_tag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracing-Based HF Module Hierarchy Builder\n",
    "\n",
    "This approach uses forward hooks to trace actual execution flow and build more accurate hierarchy mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TracingHierarchyBuilder:\n",
    "    \"\"\"Tracing-based HF hierarchy builder using forward hooks.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tag_stack = []\n",
    "        self.execution_trace = []\n",
    "        self.operation_context = {}\n",
    "        self.hooks = []\n",
    "        \n",
    "    def is_hf_class(self, module):\n",
    "        \"\"\"Check if a module is a HuggingFace class\"\"\"\n",
    "        module_path = module.__class__.__module__\n",
    "        return module_path.startswith('transformers')\n",
    "    \n",
    "    def should_create_hierarchy_level(self, module):\n",
    "        \"\"\"Determine if module should create a new hierarchy level\"\"\"\n",
    "        if self.is_hf_class(module):\n",
    "            return True\n",
    "        # Include some important torch.nn modules\n",
    "        important_torch_nn = ['LayerNorm', 'Embedding']\n",
    "        return module.__class__.__name__ in important_torch_nn\n",
    "    \n",
    "    def extract_module_info(self, module_name: str, module):\n",
    "        \"\"\"Extract module information for hierarchy building\"\"\"\n",
    "        name_parts = module_name.split(\".\")\n",
    "        \n",
    "        # Check if this is an indexed module (e.g., layer.0)\n",
    "        is_indexed_module = False\n",
    "        module_index = None\n",
    "        \n",
    "        if len(name_parts) >= 2:\n",
    "            last_part = name_parts[-1]\n",
    "            second_last_part = name_parts[-2]\n",
    "            \n",
    "            if (last_part.isdigit() and \n",
    "                second_last_part in ['layer', 'layers', 'block', 'blocks', 'h']):\n",
    "                is_indexed_module = True\n",
    "                module_index = last_part\n",
    "        \n",
    "        return {\n",
    "            'class_name': module.__class__.__name__,\n",
    "            'module_index': module_index,\n",
    "            'full_name': module_name,\n",
    "            'is_indexed': is_indexed_module,\n",
    "            'name_parts': name_parts,\n",
    "        }\n",
    "    \n",
    "    def create_pre_hook(self, module_info):\n",
    "        \"\"\"Create pre-forward hook to push tag onto stack\"\"\"\n",
    "        def pre_hook(module, inputs):\n",
    "            # Get parent context from stack\n",
    "            parent_tag = self.tag_stack[-1] if self.tag_stack else \"\"\n",
    "            \n",
    "            # Build current class name with index if needed\n",
    "            if module_info['is_indexed']:\n",
    "                current_class_name = f\"{module_info['class_name']}.{module_info['module_index']}\"\n",
    "            else:\n",
    "                current_class_name = module_info['class_name']\n",
    "            \n",
    "            # Build hierarchical tag\n",
    "            hierarchical_tag = f\"{parent_tag}/{current_class_name}\"\n",
    "            self.tag_stack.append(hierarchical_tag)\n",
    "            \n",
    "            # Record execution trace\n",
    "            trace_entry = {\n",
    "                'module_name': module_info['full_name'],\n",
    "                'tag': hierarchical_tag,\n",
    "                'action': 'enter',\n",
    "                'stack_depth': len(self.tag_stack),\n",
    "                'execution_order': len(self.execution_trace)\n",
    "            }\n",
    "            self.execution_trace.append(trace_entry)\n",
    "            \n",
    "            # Record in operation context\n",
    "            self.operation_context[module_info['full_name']] = {\n",
    "                \"tag\": hierarchical_tag,\n",
    "                \"module_class\": module_info['class_name'],\n",
    "                \"creates_hierarchy\": True,\n",
    "                \"stack_depth\": len(self.tag_stack),\n",
    "                \"execution_order\": len(self.execution_trace) - 1,\n",
    "                \"module_info\": module_info\n",
    "            }\n",
    "            \n",
    "        return pre_hook\n",
    "    \n",
    "    def create_post_hook(self, module_info):\n",
    "        \"\"\"Create post-forward hook to pop tag from stack\"\"\"\n",
    "        def post_hook(module, inputs, outputs):\n",
    "            # Record exit\n",
    "            trace_entry = {\n",
    "                'module_name': module_info['full_name'],\n",
    "                'tag': self.tag_stack[-1] if self.tag_stack else \"\",\n",
    "                'action': 'exit',\n",
    "                'stack_depth': len(self.tag_stack),\n",
    "                'execution_order': len(self.execution_trace)\n",
    "            }\n",
    "            self.execution_trace.append(trace_entry)\n",
    "            \n",
    "            # Pop the tag when module execution completes\n",
    "            if self.tag_stack:\n",
    "                self.tag_stack.pop()\n",
    "                \n",
    "        return post_hook\n",
    "    \n",
    "    def register_hooks(self, model):\n",
    "        \"\"\"Register forward hooks for tracing\"\"\"\n",
    "        # Initialize stack with root module tag\n",
    "        root_tag = f\"/{model.__class__.__name__}\"\n",
    "        self.tag_stack = [root_tag]\n",
    "        \n",
    "        # Register hooks on all modules\n",
    "        for name, module in model.named_modules():\n",
    "            if name:  # Skip root module\n",
    "                module_info = self.extract_module_info(name, module)\n",
    "                \n",
    "                # Only hook modules that should create hierarchy levels\n",
    "                if self.should_create_hierarchy_level(module):\n",
    "                    # Register pre-hook\n",
    "                    pre_hook = module.register_forward_pre_hook(\n",
    "                        self.create_pre_hook(module_info)\n",
    "                    )\n",
    "                    self.hooks.append(pre_hook)\n",
    "                    \n",
    "                    # Register post-hook\n",
    "                    post_hook = module.register_forward_hook(\n",
    "                        self.create_post_hook(module_info)\n",
    "                    )\n",
    "                    self.hooks.append(post_hook)\n",
    "    \n",
    "    def remove_hooks(self):\n",
    "        \"\"\"Remove all registered hooks\"\"\"\n",
    "        for hook in self.hooks:\n",
    "            hook.remove()\n",
    "        self.hooks.clear()\n",
    "    \n",
    "    def trace_model_execution(self, model, example_inputs):\n",
    "        \"\"\"Trace model execution to build hierarchy mapping\"\"\"\n",
    "        self.register_hooks(model)\n",
    "        \n",
    "        try:\n",
    "            # Run model forward pass to trigger hooks\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                _ = model(*example_inputs)\n",
    "        finally:\n",
    "            self.remove_hooks()\n",
    "    \n",
    "    def get_hierarchy_mapping(self):\n",
    "        \"\"\"Get the traced hierarchy mapping\"\"\"\n",
    "        hierarchy_mapping = {}\n",
    "        \n",
    "        for module_name, context in self.operation_context.items():\n",
    "            hierarchy_mapping[module_name] = context['tag']\n",
    "        \n",
    "        return hierarchy_mapping\n",
    "    \n",
    "    def get_execution_summary(self):\n",
    "        \"\"\"Get summary of execution trace\"\"\"\n",
    "        return {\n",
    "            'total_modules_traced': len(self.operation_context),\n",
    "            'execution_steps': len(self.execution_trace),\n",
    "            'max_stack_depth': max([t['stack_depth'] for t in self.execution_trace] + [0]),\n",
    "            'hierarchy_mapping': self.get_hierarchy_mapping()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Tracing-Based Hierarchy Mapping\n",
    "\n",
    "Now let's test the tracing approach and compare it with our static approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example inputs prepared:\n",
      "Input IDs shape: torch.Size([1, 64])\n",
      "Attention mask shape: torch.Size([1, 64])\n",
      "\n",
      "Creating tracing hierarchy builder...\n",
      "\n",
      "Tracing model execution...\n",
      "\n",
      "Tracing completed!\n",
      "Execution summary: {'total_modules_traced': 25, 'execution_steps': 50, 'max_stack_depth': 6, 'hierarchy_mapping': {'embeddings': '/BertModel/BertEmbeddings', 'embeddings.word_embeddings': '/BertModel/BertEmbeddings/Embedding', 'embeddings.token_type_embeddings': '/BertModel/BertEmbeddings/Embedding', 'embeddings.position_embeddings': '/BertModel/BertEmbeddings/Embedding', 'embeddings.LayerNorm': '/BertModel/BertEmbeddings/LayerNorm', 'encoder': '/BertModel/BertEncoder', 'encoder.layer.0': '/BertModel/BertEncoder/BertLayer.0', 'encoder.layer.0.attention': '/BertModel/BertEncoder/BertLayer.0/BertAttention', 'encoder.layer.0.attention.self': '/BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention', 'encoder.layer.0.attention.output': '/BertModel/BertEncoder/BertLayer.0/BertAttention/BertSelfOutput', 'encoder.layer.0.attention.output.LayerNorm': '/BertModel/BertEncoder/BertLayer.0/BertAttention/BertSelfOutput/LayerNorm', 'encoder.layer.0.intermediate': '/BertModel/BertEncoder/BertLayer.0/BertIntermediate', 'encoder.layer.0.intermediate.intermediate_act_fn': '/BertModel/BertEncoder/BertLayer.0/BertIntermediate/GELUActivation', 'encoder.layer.0.output': '/BertModel/BertEncoder/BertLayer.0/BertOutput', 'encoder.layer.0.output.LayerNorm': '/BertModel/BertEncoder/BertLayer.0/BertOutput/LayerNorm', 'encoder.layer.1': '/BertModel/BertEncoder/BertLayer.1', 'encoder.layer.1.attention': '/BertModel/BertEncoder/BertLayer.1/BertAttention', 'encoder.layer.1.attention.self': '/BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention', 'encoder.layer.1.attention.output': '/BertModel/BertEncoder/BertLayer.1/BertAttention/BertSelfOutput', 'encoder.layer.1.attention.output.LayerNorm': '/BertModel/BertEncoder/BertLayer.1/BertAttention/BertSelfOutput/LayerNorm', 'encoder.layer.1.intermediate': '/BertModel/BertEncoder/BertLayer.1/BertIntermediate', 'encoder.layer.1.intermediate.intermediate_act_fn': '/BertModel/BertEncoder/BertLayer.1/BertIntermediate/GELUActivation', 'encoder.layer.1.output': '/BertModel/BertEncoder/BertLayer.1/BertOutput', 'encoder.layer.1.output.LayerNorm': '/BertModel/BertEncoder/BertLayer.1/BertOutput/LayerNorm', 'pooler': '/BertModel/BertPooler'}}\n"
     ]
    }
   ],
   "source": [
    "# Prepare example inputs for tracing\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "text = \"Hello world, this is a test sentence.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", max_length=64, padding=\"max_length\", truncation=True)\n",
    "example_inputs = (inputs[\"input_ids\"], inputs[\"attention_mask\"])\n",
    "\n",
    "print(f\"Example inputs prepared:\")\n",
    "print(f\"Input IDs shape: {example_inputs[0].shape}\")\n",
    "print(f\"Attention mask shape: {example_inputs[1].shape}\")\n",
    "\n",
    "# Create tracing hierarchy builder\n",
    "print(\"\\nCreating tracing hierarchy builder...\")\n",
    "tracer = TracingHierarchyBuilder()\n",
    "\n",
    "# Trace model execution\n",
    "print(\"\\nTracing model execution...\")\n",
    "tracer.trace_model_execution(model, example_inputs)\n",
    "\n",
    "# Get results\n",
    "traced_mapping = tracer.get_hierarchy_mapping()\n",
    "execution_summary = tracer.get_execution_summary()\n",
    "\n",
    "print(f\"\\nTracing completed!\")\n",
    "print(f\"Execution summary: {execution_summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traced Hierarchy Mapping:\n",
      "======================================================================\n",
      "embeddings                               -> /BertModel/BertEmbeddings\n",
      "embeddings.LayerNorm                     -> /BertModel/BertEmbeddings/LayerNorm\n",
      "embeddings.position_embeddings           -> /BertModel/BertEmbeddings/Embedding\n",
      "embeddings.token_type_embeddings         -> /BertModel/BertEmbeddings/Embedding\n",
      "embeddings.word_embeddings               -> /BertModel/BertEmbeddings/Embedding\n",
      "encoder                                  -> /BertModel/BertEncoder\n",
      "encoder.layer.0                          -> /BertModel/BertEncoder/BertLayer.0\n",
      "encoder.layer.0.attention                -> /BertModel/BertEncoder/BertLayer.0/BertAttention\n",
      "encoder.layer.0.attention.output         -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSelfOutput\n",
      "encoder.layer.0.attention.output.LayerNorm -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSelfOutput/LayerNorm\n",
      "encoder.layer.0.attention.self           -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention\n",
      "encoder.layer.0.intermediate             -> /BertModel/BertEncoder/BertLayer.0/BertIntermediate\n",
      "encoder.layer.0.intermediate.intermediate_act_fn -> /BertModel/BertEncoder/BertLayer.0/BertIntermediate/GELUActivation\n",
      "encoder.layer.0.output                   -> /BertModel/BertEncoder/BertLayer.0/BertOutput\n",
      "encoder.layer.0.output.LayerNorm         -> /BertModel/BertEncoder/BertLayer.0/BertOutput/LayerNorm\n",
      "encoder.layer.1                          -> /BertModel/BertEncoder/BertLayer.1\n",
      "encoder.layer.1.attention                -> /BertModel/BertEncoder/BertLayer.1/BertAttention\n",
      "encoder.layer.1.attention.output         -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSelfOutput\n",
      "encoder.layer.1.attention.output.LayerNorm -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSelfOutput/LayerNorm\n",
      "encoder.layer.1.attention.self           -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention\n",
      "encoder.layer.1.intermediate             -> /BertModel/BertEncoder/BertLayer.1/BertIntermediate\n",
      "encoder.layer.1.intermediate.intermediate_act_fn -> /BertModel/BertEncoder/BertLayer.1/BertIntermediate/GELUActivation\n",
      "encoder.layer.1.output                   -> /BertModel/BertEncoder/BertLayer.1/BertOutput\n",
      "encoder.layer.1.output.LayerNorm         -> /BertModel/BertEncoder/BertLayer.1/BertOutput/LayerNorm\n",
      "pooler                                   -> /BertModel/BertPooler\n",
      "\n",
      "Found 25 modules with traced hierarchy tags\n"
     ]
    }
   ],
   "source": [
    "# Display traced hierarchy mapping\n",
    "print(\"Traced Hierarchy Mapping:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for module_name, hierarchy_tag in sorted(traced_mapping.items()):\n",
    "    print(f\"{module_name:40} -> {hierarchy_tag}\")\n",
    "\n",
    "print(f\"\\nFound {len(traced_mapping)} modules with traced hierarchy tags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Static vs Tracing Approaches\n",
    "\n",
    "Let's compare the static and tracing-based hierarchy mappings to see the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Summary:\n",
      "==================================================\n",
      "Static mapping modules: 47\n",
      "Traced mapping modules: 25\n",
      "Common modules: 25\n",
      "Only in static: 22\n",
      "Only in traced: 0\n",
      "\n",
      "Tag Comparison:\n",
      "Matching tags: 17/25\n",
      "Different tags: 8\n",
      "\n",
      "First few tag differences:\n",
      "  embeddings.token_type_embeddings\n",
      "    Static:  /BertModel/BertEmbeddings\n",
      "    Traced:  /BertModel/BertEmbeddings/Embedding\n",
      "  embeddings.position_embeddings\n",
      "    Static:  /BertModel/BertEmbeddings\n",
      "    Traced:  /BertModel/BertEmbeddings/Embedding\n",
      "  encoder.layer.1.output.LayerNorm\n",
      "    Static:  /BertModel/BertEncoder/BertLayer.1/BertOutput\n",
      "    Traced:  /BertModel/BertEncoder/BertLayer.1/BertOutput/LayerNorm\n",
      "  encoder.layer.0.output.LayerNorm\n",
      "    Static:  /BertModel/BertEncoder/BertLayer.0/BertOutput\n",
      "    Traced:  /BertModel/BertEncoder/BertLayer.0/BertOutput/LayerNorm\n",
      "  encoder.layer.0.attention.output.LayerNorm\n",
      "    Static:  /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSelfOutput\n",
      "    Traced:  /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSelfOutput/LayerNorm\n",
      "    ... and 3 more differences\n"
     ]
    }
   ],
   "source": [
    "def compare_hierarchy_mappings(static_mapping, traced_mapping):\n",
    "    \"\"\"Compare static and traced hierarchy mappings\"\"\"\n",
    "    \n",
    "    # Find common modules\n",
    "    static_modules = set(static_mapping.keys())\n",
    "    traced_modules = set(traced_mapping.keys())\n",
    "    common_modules = static_modules & traced_modules\n",
    "    \n",
    "    # Find differences\n",
    "    only_static = static_modules - traced_modules\n",
    "    only_traced = traced_modules - static_modules\n",
    "    \n",
    "    print(\"Comparison Summary:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Static mapping modules: {len(static_modules)}\")\n",
    "    print(f\"Traced mapping modules: {len(traced_modules)}\")\n",
    "    print(f\"Common modules: {len(common_modules)}\")\n",
    "    print(f\"Only in static: {len(only_static)}\")\n",
    "    print(f\"Only in traced: {len(only_traced)}\")\n",
    "    \n",
    "    # Check for tag differences in common modules\n",
    "    tag_differences = []\n",
    "    tag_matches = 0\n",
    "    \n",
    "    for module in common_modules:\n",
    "        static_tag = static_mapping[module]\n",
    "        traced_tag = traced_mapping[module]\n",
    "        \n",
    "        if static_tag == traced_tag:\n",
    "            tag_matches += 1\n",
    "        else:\n",
    "            tag_differences.append({\n",
    "                'module': module,\n",
    "                'static': static_tag,\n",
    "                'traced': traced_tag\n",
    "            })\n",
    "    \n",
    "    print(f\"\\nTag Comparison:\")\n",
    "    print(f\"Matching tags: {tag_matches}/{len(common_modules)}\")\n",
    "    print(f\"Different tags: {len(tag_differences)}\")\n",
    "    \n",
    "    # Show some differences\n",
    "    if tag_differences:\n",
    "        print(f\"\\nFirst few tag differences:\")\n",
    "        for diff in tag_differences[:5]:\n",
    "            print(f\"  {diff['module']:30}\")\n",
    "            print(f\"    Static:  {diff['static']}\")\n",
    "            print(f\"    Traced:  {diff['traced']}\")\n",
    "        \n",
    "        if len(tag_differences) > 5:\n",
    "            print(f\"    ... and {len(tag_differences) - 5} more differences\")\n",
    "    \n",
    "    # Show modules only in traced (key insight)\n",
    "    if only_traced:\n",
    "        print(f\"\\nModules only in traced mapping (execution-only):\")\n",
    "        for module in sorted(list(only_traced))[:5]:\n",
    "            print(f\"  {module:30} -> {traced_mapping[module]}\")\n",
    "        if len(only_traced) > 5:\n",
    "            print(f\"    ... and {len(only_traced) - 5} more\")\n",
    "    \n",
    "    return {\n",
    "        'static_count': len(static_modules),\n",
    "        'traced_count': len(traced_modules),\n",
    "        'common_count': len(common_modules),\n",
    "        'tag_matches': tag_matches,\n",
    "        'tag_differences': len(tag_differences),\n",
    "        'differences': tag_differences\n",
    "    }\n",
    "\n",
    "# Compare the mappings\n",
    "comparison = compare_hierarchy_mappings(static_hierarchy_mapping, traced_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution Trace Analysis\n",
    "\n",
    "Let's analyze the execution trace to understand the call flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Trace Analysis:\n",
      "==================================================\n",
      "First 10 execution steps:\n",
      " 0:   → embeddings\n",
      " 1:     → embeddings.word_embeddings\n",
      " 2:     ← embeddings.word_embeddings\n",
      " 3:     → embeddings.token_type_embeddings\n",
      " 4:     ← embeddings.token_type_embeddings\n",
      " 5:     → embeddings.position_embeddings\n",
      " 6:     ← embeddings.position_embeddings\n",
      " 7:     → embeddings.LayerNorm\n",
      " 8:     ← embeddings.LayerNorm\n",
      " 9:   ← embeddings\n",
      "... and 40 more steps\n",
      "\n",
      "Module execution order:\n",
      " 0: embeddings                     -> /BertModel/BertEmbeddings\n",
      " 1: embeddings.word_embeddings     -> /BertModel/BertEmbeddings/Embedding\n",
      " 3: embeddings.token_type_embeddings -> /BertModel/BertEmbeddings/Embedding\n",
      " 5: embeddings.position_embeddings -> /BertModel/BertEmbeddings/Embedding\n",
      " 7: embeddings.LayerNorm           -> /BertModel/BertEmbeddings/LayerNorm\n",
      "10: encoder                        -> /BertModel/BertEncoder\n",
      "11: encoder.layer.0                -> /BertModel/BertEncoder/BertLayer.0\n",
      "12: encoder.layer.0.attention      -> /BertModel/BertEncoder/BertLayer.0/BertAttention\n",
      "13: encoder.layer.0.attention.self -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention\n",
      "15: encoder.layer.0.attention.output -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSelfOutput\n",
      "16: encoder.layer.0.attention.output.LayerNorm -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSelfOutput/LayerNorm\n",
      "20: encoder.layer.0.intermediate   -> /BertModel/BertEncoder/BertLayer.0/BertIntermediate\n",
      "21: encoder.layer.0.intermediate.intermediate_act_fn -> /BertModel/BertEncoder/BertLayer.0/BertIntermediate/GELUActivation\n",
      "24: encoder.layer.0.output         -> /BertModel/BertEncoder/BertLayer.0/BertOutput\n",
      "25: encoder.layer.0.output.LayerNorm -> /BertModel/BertEncoder/BertLayer.0/BertOutput/LayerNorm\n",
      "29: encoder.layer.1                -> /BertModel/BertEncoder/BertLayer.1\n",
      "30: encoder.layer.1.attention      -> /BertModel/BertEncoder/BertLayer.1/BertAttention\n",
      "31: encoder.layer.1.attention.self -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention\n",
      "33: encoder.layer.1.attention.output -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSelfOutput\n",
      "34: encoder.layer.1.attention.output.LayerNorm -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSelfOutput/LayerNorm\n",
      "38: encoder.layer.1.intermediate   -> /BertModel/BertEncoder/BertLayer.1/BertIntermediate\n",
      "39: encoder.layer.1.intermediate.intermediate_act_fn -> /BertModel/BertEncoder/BertLayer.1/BertIntermediate/GELUActivation\n",
      "42: encoder.layer.1.output         -> /BertModel/BertEncoder/BertLayer.1/BertOutput\n",
      "43: encoder.layer.1.output.LayerNorm -> /BertModel/BertEncoder/BertLayer.1/BertOutput/LayerNorm\n",
      "48: pooler                         -> /BertModel/BertPooler\n",
      "\n",
      "Max stack depth reached: 6\n"
     ]
    }
   ],
   "source": [
    "# Analyze execution trace\n",
    "print(\"Execution Trace Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Show first few trace entries\n",
    "print(\"First 10 execution steps:\")\n",
    "for i, trace in enumerate(tracer.execution_trace[:10]):\n",
    "    indent = \"  \" * (trace['stack_depth'] - 1)\n",
    "    action_symbol = \"→\" if trace['action'] == 'enter' else \"←\"\n",
    "    print(f\"{i:2d}: {indent}{action_symbol} {trace['module_name']}\")\n",
    "\n",
    "if len(tracer.execution_trace) > 10:\n",
    "    print(f\"... and {len(tracer.execution_trace) - 10} more steps\")\n",
    "\n",
    "# Show execution order of modules\n",
    "print(f\"\\nModule execution order:\")\n",
    "execution_order = {}\n",
    "for module_name, context in tracer.operation_context.items():\n",
    "    execution_order[context['execution_order']] = (module_name, context['tag'])\n",
    "\n",
    "for order in sorted(execution_order.keys()):\n",
    "    module_name, tag = execution_order[order]\n",
    "    print(f\"{order:2d}: {module_name:30} -> {tag}\")\n",
    "\n",
    "print(f\"\\nMax stack depth reached: {execution_summary['max_stack_depth']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Insights\n",
    "\n",
    "**Static vs Tracing Comparison:**\n",
    "\n",
    "1. **Static Approach**: Fast, comprehensive, covers all modules in model structure\n",
    "2. **Tracing Approach**: Accurate, execution-based, includes important torch.nn modules like LayerNorm\n",
    "3. **Key Difference**: Tracing captures modules that actually execute and includes torch.nn modules that contribute to hierarchy\n",
    "\n",
    "**When to Use:**\n",
    "- **Static**: When you need fast analysis of model structure\n",
    "- **Tracing**: When you need accurate operation-to-module mapping for ONNX export\n",
    "- **Both**: For validation and comprehensive coverage\n",
    "\n",
    "**Tracing Advantages:**\n",
    "- Captures actual execution flow\n",
    "- Includes important torch.nn modules (LayerNorm, Embedding)\n",
    "- Provides execution order and timing\n",
    "- Better for dynamic module behavior\n",
    "\n",
    "**Test with different models by changing MODEL_NAME above!**"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Import the actual TracingHierarchyBuilder from modelexport.core\nimport sys\nsys.path.append('../..')  # Add project root to path\n\nfrom modelexport.core.tracing_hierarchy_builder import TracingHierarchyBuilder\nfrom modelexport.core.model_input_generator import generate_dummy_inputs\nfrom rich.console import Console\nfrom rich.tree import Tree\nfrom rich.text import Text\nfrom rich.table import Table\nfrom rich.panel import Panel\nimport json\n\nconsole = Console()\n\n# Create inputs using the model_input_generator\nprint(\"Generating inputs using model_input_generator...\")\ndummy_inputs = generate_dummy_inputs(MODEL_NAME, exporter=\"onnx\")\nprint(f\"Generated inputs: {list(dummy_inputs.keys())}\")\n\n# Create the actual TracingHierarchyBuilder\nprint(\"\\nCreating TracingHierarchyBuilder from modelexport.core...\")\ncore_tracer = TracingHierarchyBuilder()\n\n# Trace the model\nprint(\"Tracing model execution...\")\ncore_tracer.trace_model_execution(model, dummy_inputs)\n\n# Get the execution summary\ncore_summary = core_tracer.get_execution_summary()\n\nprint(f\"\\n✅ Tracing completed!\")\nprint(f\"Total modules traced: {core_summary['total_modules_traced']}\")\nprint(f\"Total modules: {core_summary['total_modules']}\")\nprint(f\"Execution steps: {core_summary['execution_steps']}\")\n\n# Get the hierarchy data\nmodule_hierarchy = core_summary.get('module_hierarchy', {})\n\n# Function to create styled text (main: detail)\ndef create_styled_text(main_text, detail_text, main_style=\"bold\", detail_style=\"dim\"):\n    \"\"\"Create styled text with main text and detail text in gray.\"\"\"\n    styled_text = Text()\n    styled_text.append(main_text, style=main_style)\n    styled_text.append(\": \", style=\"white\")\n    styled_text.append(detail_text, style=detail_style)\n    return styled_text\n\n# Create a summary panel\nstats_table = Table(show_header=False, box=None)\nstats_table.add_column(style=\"bold cyan\")\nstats_table.add_column(style=\"bold yellow\")\n\nstats_table.add_row(\"Total Modules Traced\", str(core_summary['total_modules_traced']))\nstats_table.add_row(\"Total Modules\", str(core_summary['total_modules']))\nstats_table.add_row(\"Execution Steps\", str(core_summary['execution_steps']))\nstats_table.add_row(\"Hierarchy Entries\", str(len(core_summary.get('hierarchy_mapping', {}))))\n\nconsole.print(Panel(stats_table, title=\"[bold blue]Execution Summary[/bold blue]\", border_style=\"blue\"))\n\n# Display hierarchy as a tree\nprint(\"\\n🌳 Module Hierarchy Tree:\")\nprint(\"=\" * 80)\n\n# Get root info\nroot_info = module_hierarchy.get(\"\", {})\nroot_class = root_info.get('class_name', model.__class__.__name__)\n\n# Create the tree\ntree = Tree(f\"[bold bright_magenta]{root_class}[/bold bright_magenta]\")\n\ndef build_tree(tree_node, parent_path, hierarchy_data, processed=None):\n    \"\"\"Build tree showing the module hierarchy with proper parent-child relationships.\"\"\"\n    if processed is None:\n        processed = set()\n    \n    # Find immediate children\n    immediate_children = []\n    \n    for path, info in hierarchy_data.items():\n        if path in processed or not path:  # Skip if already processed or is root\n            continue\n            \n        if parent_path == \"\":\n            # Root level - find paths with no dots\n            if \".\" not in path:\n                immediate_children.append((path, info))\n        else:\n            # Check if this path is a child of parent_path\n            if path.startswith(parent_path + \".\"):\n                suffix = path[len(parent_path + \".\"):]\n                \n                # Case 1: Direct child (no dots in suffix)\n                if \".\" not in suffix:\n                    immediate_children.append((path, info))\n                # Case 2: Numbered pattern (e.g., layer.0)\n                else:\n                    parts = suffix.split(\".\")\n                    # Match only exact patterns like \"layer.0\"\n                    if len(parts) == 2 and parts[1].isdigit():\n                        immediate_children.append((path, info))\n    \n    # Sort children for consistent display\n    immediate_children.sort(key=lambda x: x[0])\n    \n    # Add children to tree\n    for child_path, child_info in immediate_children:\n        processed.add(child_path)\n        \n        class_name = child_info.get('class_name', 'Unknown')\n        \n        # Create styled text\n        styled_text = create_styled_text(class_name, child_path, \"bold bright_green\", \"bright_cyan\")\n        \n        child_node = tree_node.add(styled_text)\n        \n        # Recursively add children\n        build_tree(child_node, child_path, hierarchy_data, processed)\n\n# Build the tree\nbuild_tree(tree, \"\", module_hierarchy)\n\n# Display the tree\nconsole.print(tree)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Testing with ResNet-50\n\nNow let's test with ResNet-50 to see the issue with ResNetConvLayer showing 0 nodes:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Test ResNet with the fixed HTP exporter\nimport sys\nsys.path.append('../..')  # Add project root to path\n\nfrom transformers import AutoModel\nfrom modelexport.strategies.htp import HTPExporter\nfrom modelexport.core.model_input_generator import generate_dummy_inputs\nfrom rich.tree import Tree\nfrom rich.console import Console\nfrom rich.style import Style\nfrom rich.text import Text\n\n# Initialize\nconsole = Console()\nmodel_name = \"microsoft/resnet-50\"\nmodel = AutoModel.from_pretrained(model_name)\n\n# Export with hierarchy preservation AND include torch.nn children\nconsole.print(f\"\\n🔧 Exporting {model_name} with hierarchy preservation (include torch.nn)...\", style=\"bold cyan\")\nexporter = HTPExporter(verbose=False, include_torch_nn_children=True)\nexport_result = exporter.export(\n    model=model,\n    output_path=\"resnet_fixed.onnx\",\n    model_name_or_path=model_name\n)\n\n# Display summary\nconsole.print(\"\\n📊 Export Summary\", style=\"bold green\")\nconsole.print(f\"Total modules in hierarchy: {len(exporter._hierarchy_data)}\")\nconsole.print(f\"Total ONNX operations: {len(exporter._tagged_nodes)}\")\n\n# Build hierarchy tree focusing on ResNetConvLayer\nconsole.print(\"\\n🌳 Module Hierarchy (ResNetConvLayer focus):\", style=\"bold blue\")\ntree = Tree(\"ResNetModel\", style=\"bold magenta\")\n\ndef add_resnet_conv_layers(node, path=\"\", hierarchy_data=None, tagged_nodes=None, depth=0, max_depth=4):\n    \"\"\"Add ResNetConvLayer nodes to tree with counts.\"\"\"\n    if depth > max_depth:\n        return\n    \n    # Find immediate children\n    immediate_children = []\n    for child_path, child_info in hierarchy_data.items():\n        if child_path.startswith(path + \".\") and child_path != path:\n            parts = child_path[len(path)+1:].split('.')\n            if len(parts) == 1 or (len(parts) == 2 and parts[1].isdigit()):\n                immediate_children.append((child_path, child_info))\n    \n    # Filter to show ResNetConvLayer and its parents\n    for child_path, child_info in sorted(immediate_children):\n        class_name = child_info.get('class_name', 'Unknown')\n        traced_tag = child_info.get('traced_tag', '')\n        \n        # Count nodes with correct logic\n        node_count = 0\n        for tag in tagged_nodes.values():\n            if tag == traced_tag or tag.startswith(traced_tag + \"/\"):\n                node_count += 1\n        \n        # Show ResNetConvLayer and important parents\n        if class_name in ['ResNetConvLayer', 'ResNetBottleNeckLayer', 'ResNetStage', 'ResNetEncoder']:\n            # Style based on node count\n            if node_count == 0:\n                style = \"red\"\n                issue = \" ❌\"\n            elif node_count < 5:\n                style = \"yellow\" \n                issue = \" ✅\"\n            else:\n                style = \"green\"\n                issue = \" ✅\"\n            \n            # Create text with styled count\n            text = Text(f\"{class_name}: {child_path.split('.')[-1]}\")\n            text.append(f\" ({node_count} nodes){issue}\", style=style)\n            \n            child_node = node.add(text)\n            \n            # Recurse for important nodes\n            if class_name != 'ResNetConvLayer':  # Don't recurse into ResNetConvLayer\n                add_resnet_conv_layers(child_node, child_path, hierarchy_data, tagged_nodes, depth + 1, max_depth)\n\n# Show only ResNetEncoder branch\nfor path, info in exporter._hierarchy_data.items():\n    if path == 'encoder':\n        node = tree.add(\"ResNetEncoder\")\n        add_resnet_conv_layers(node, path, exporter._hierarchy_data, exporter._tagged_nodes)\n        break\n\nconsole.print(tree)\n\n# Show the fix explanation\nconsole.print(\"\\n📝 Fix Explanation:\", style=\"bold yellow\")\nconsole.print(\"The issue was that ONNX node names had a double 'layer' pattern:\")\nconsole.print(\"  ❌ ONNX: /encoder/stages.0/layers.0/layer/layer.0/convolution/Conv\")\nconsole.print(\"  ✅ Hierarchy: encoder.stages.0.layers.0.layer.0.convolution\")\nconsole.print(\"\\nThe fix in _extract_scope_from_node() now handles this pattern:\")\nconsole.print(\"  - Detects 'layer/layer.N' patterns\")\nconsole.print(\"  - Converts to 'layer.N' to match hierarchy data\")\nconsole.print(\"  - Operations are now correctly tagged to ResNetConvLayer modules\")\n\n# Verify some specific ResNetConvLayer nodes\nconsole.print(\"\\n🔍 Sample ResNetConvLayer Verification:\", style=\"bold cyan\")\nsample_paths = [\n    \"encoder.stages.0.layers.0.layer.0\",\n    \"encoder.stages.0.layers.0.layer.1\",\n    \"encoder.stages.0.layers.0.layer.2\"\n]\n\nfor path in sample_paths:\n    if path in exporter._hierarchy_data:\n        info = exporter._hierarchy_data[path]\n        tag = info.get('traced_tag')\n        node_count = sum(1 for t in exporter._tagged_nodes.values() if t == tag or t.startswith(tag + \"/\"))\n        console.print(f\"\\n{path}:\")\n        console.print(f\"  Nodes: {node_count} {'✅' if node_count > 0 else '❌'}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## ResNet Issue Fix Demonstration\n\nThis section demonstrates the fix for the ResNet issue where `ResNetConvLayer` modules were showing 0 nodes due to ONNX node naming mismatches.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Test with ResNet-50\nprint(\"Testing with ResNet-50...\")\nprint(\"=\" * 80)\n\n# Load ResNet-50\nresnet_model = AutoModel.from_pretrained(\"microsoft/resnet-50\")\nprint(f\"Model class: {resnet_model.__class__.__name__}\")\n\n# Generate inputs\nresnet_inputs = generate_dummy_inputs(\"microsoft/resnet-50\", exporter=\"onnx\")\nprint(f\"Generated inputs: {list(resnet_inputs.keys())}\")\n\n# Create tracer\nresnet_tracer = TracingHierarchyBuilder()\n\n# Trace the model\nprint(\"\\nTracing ResNet-50 execution...\")\nresnet_tracer.trace_model_execution(resnet_model, resnet_inputs)\n\n# Get summary\nresnet_summary = resnet_tracer.get_execution_summary()\nresnet_hierarchy = resnet_summary['module_hierarchy']\n\nprint(f\"\\nTotal modules traced: {len(resnet_hierarchy)}\")\n\n# Look for ResNetConvLayer modules\nprint(\"\\nLooking for ResNetConvLayer modules:\")\nprint(\"-\" * 80)\n\nconv_layers = []\nfor path, info in resnet_hierarchy.items():\n    if info.get('class_name') == 'ResNetConvLayer':\n        conv_layers.append((path, info))\n\nprint(f\"Found {len(conv_layers)} ResNetConvLayer modules\")\n\n# Show first few\nfor path, info in conv_layers[:3]:\n    print(f\"\\nPath: {path}\")\n    print(f\"  Class: {info.get('class_name')}\")\n    print(f\"  Tag: {info.get('traced_tag')}\")\n    \n    # Look for child modules of this ResNetConvLayer\n    print(f\"  Looking for children of {path}:\")\n    child_count = 0\n    for child_path, child_info in resnet_hierarchy.items():\n        if child_path.startswith(path + \".\") and child_path != path:\n            print(f\"    - {child_path}: {child_info.get('class_name')} (tag: {child_info.get('traced_tag')})\")\n            child_count += 1\n    \n    if child_count == 0:\n        print(f\"    ❌ No children found in hierarchy! This explains the 0 nodes issue.\")\n        \n        # Let's check the actual module structure\n        print(f\"\\n  Checking actual module structure of {path}:\")\n        module = resnet_model\n        for part in path.split('.'):\n            if part:\n                module = getattr(module, part)\n        \n        print(f\"  Module has the following torch.nn children:\")\n        for name, child in module.named_children():\n            print(f\"    - {name}: {type(child).__name__}\")\n\nprint(\"\\n🔴 Issue: ResNetConvLayer has torch.nn children (Conv2d, BatchNorm2d, ReLU) that are not captured\")\nprint(\"    in the hierarchy because the current TracingHierarchyBuilder includes ALL modules.\")\nprint(\"    However, when filtered by should_include_in_hierarchy for MUST-002 compliance,\")\nprint(\"    these torch.nn modules would be excluded, causing ResNetConvLayer to show 0 nodes.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}