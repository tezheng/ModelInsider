--- baseline
+++ iteration_1
@@ -1,159 +1,310 @@
-

 ================================================================================

-📋 STEP 1/8: MODEL PREPARATION

+HTP EXPORT FULL REPORT

 ================================================================================

-✅ Model loaded: BertModel (48 modules, 4.4M parameters)

-🎯 Export target: temp/baseline/model.onnx

-⚙️ Strategy: HTP (Hierarchy-Preserving)

-✅ Model set to evaluation mode

+Generated: 2025-07-19T00:16:44Z

+

+

+MODEL INFORMATION

+----------------------------------------

+Model Name: prajjwal1/bert-tiny

+Model Class: BertModel

+Total Modules: 48

+Total Parameters: 4,385,920

+Export Strategy: HTP

+Output Path: experiments/export_monitor/iterations/iteration_001/model.onnx

+Embed Hierarchy: True

+

+INPUT GENERATION

+----------------------------------------

+Model Type: bert

+Task: feature-extraction

+Method: auto_generated

+

+Generated Inputs:

+  input_ids: shape=[2, 16], dtype=torch.int64

+  attention_mask: shape=[2, 16], dtype=torch.int64

+  token_type_ids: shape=[2, 16], dtype=torch.int64

+

+COMPLETE MODULE HIERARCHY

+----------------------------------------

+

+Module: [ROOT]

+  Class: BertModel

+  Tag: /BertModel

+  Type: huggingface

+  Execution Order: 0

+

+Module: embeddings

+  Class: BertEmbeddings

+  Tag: /BertModel/BertEmbeddings

+  Type: huggingface

+  Execution Order: 1

+

+Module: encoder

+  Class: BertEncoder

+  Tag: /BertModel/BertEncoder

+  Type: huggingface

+  Execution Order: 2

+

+Module: pooler

+  Class: BertPooler

+  Tag: /BertModel/BertPooler

+  Type: huggingface

+  Execution Order: 17

+

+Module: encoder.layer.0

+  Class: BertLayer

+  Tag: /BertModel/BertEncoder/BertLayer.0

+  Type: huggingface

+  Execution Order: 3

+

+Module: encoder.layer.1

+  Class: BertLayer

+  Tag: /BertModel/BertEncoder/BertLayer.1

+  Type: huggingface

+  Execution Order: 10

+

+Module: encoder.layer.0.attention

+  Class: BertAttention

+  Tag: /BertModel/BertEncoder/BertLayer.0/BertAttention

+  Type: huggingface

+  Execution Order: 4

+

+Module: encoder.layer.0.intermediate

+  Class: BertIntermediate

+  Tag: /BertModel/BertEncoder/BertLayer.0/BertIntermediate

+  Type: huggingface

+  Execution Order: 7

+

+Module: encoder.layer.0.output

+  Class: BertOutput

+  Tag: /BertModel/BertEncoder/BertLayer.0/BertOutput

+  Type: huggingface

+  Execution Order: 9

+

+Module: encoder.layer.1.attention

+  Class: BertAttention

+  Tag: /BertModel/BertEncoder/BertLayer.1/BertAttention

+  Type: huggingface

+  Execution Order: 11

+

+Module: encoder.layer.1.intermediate

+  Class: BertIntermediate

+  Tag: /BertModel/BertEncoder/BertLayer.1/BertIntermediate

+  Type: huggingface

+  Execution Order: 14

+

+Module: encoder.layer.1.output

+  Class: BertOutput

+  Tag: /BertModel/BertEncoder/BertLayer.1/BertOutput

+  Type: huggingface

+  Execution Order: 16

+

+Module: encoder.layer.0.attention.output

+  Class: BertSelfOutput

+  Tag: /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSelfOutput

+  Type: huggingface

+  Execution Order: 6

+

+Module: encoder.layer.0.attention.self

+  Class: BertSdpaSelfAttention

+  Tag: /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+  Type: huggingface

+  Execution Order: 5

+

+Module: encoder.layer.0.intermediate.intermediate_act_fn

+  Class: GELUActivation

+  Tag: /BertModel/BertEncoder/BertLayer.0/BertIntermediate/GELUActivation

+  Type: huggingface

+  Execution Order: 8

+

+Module: encoder.layer.1.attention.output

+  Class: BertSelfOutput

+  Tag: /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSelfOutput

+  Type: huggingface

+  Execution Order: 13

+

+Module: encoder.layer.1.attention.self

+  Class: BertSdpaSelfAttention

+  Tag: /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+  Type: huggingface

+  Execution Order: 12

+

+Module: encoder.layer.1.intermediate.intermediate_act_fn

+  Class: GELUActivation

+  Tag: /BertModel/BertEncoder/BertLayer.1/BertIntermediate/GELUActivation

+  Type: huggingface

+  Execution Order: 15

+

+Total Modules: 18

+

+[2025-07-18T16:16:48Z] onnx_export: Completed

+

+[2025-07-18T16:16:48Z] tagger_creation: Completed

+

+NODE TAGGING STATISTICS

+----------------------------------------

+Total ONNX Nodes: 136

+Tagged Nodes: 136

+Coverage: 100.0%

+  Root Nodes: 19

+  Scoped Nodes: 117

+  Unique Scopes: 32

+  Direct Matches: 83

+  Parent Matches: 34

+  Operation Matches: 0

+  Root Fallbacks: 19

+  Empty Tags: 0

+

+COMPLETE NODE MAPPINGS

+----------------------------------------

+/Cast -> /BertModel

+/Cast_1 -> /BertModel

+/Cast_2 -> /BertModel

+/Constant -> /BertModel

+/ConstantOfShape -> /BertModel

+/Constant_1 -> /BertModel

+/Constant_2 -> /BertModel

+/Constant_3 -> /BertModel

+/Constant_4 -> /BertModel

+/Constant_5 -> /BertModel

+/Constant_6 -> /BertModel

+/Equal -> /BertModel

+/Expand -> /BertModel

+/Mul -> /BertModel

+/Sub -> /BertModel

+/Unsqueeze -> /BertModel

+/Unsqueeze_1 -> /BertModel

+/Where -> /BertModel

+/Where_1 -> /BertModel

+/embeddings/Add -> /BertModel/BertEmbeddings

+/embeddings/Add_1 -> /BertModel/BertEmbeddings

+/embeddings/Constant -> /BertModel/BertEmbeddings

+/embeddings/Constant_1 -> /BertModel/BertEmbeddings

+/embeddings/LayerNorm/LayerNormalization -> /BertModel/BertEmbeddings

+/embeddings/position_embeddings/Gather -> /BertModel/BertEmbeddings

+/embeddings/token_type_embeddings/Gather -> /BertModel/BertEmbeddings

+/embeddings/word_embeddings/Gather -> /BertModel/BertEmbeddings

+/encoder/layer.0/attention/output/Add -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSelfOutput

+/encoder/layer.0/attention/output/LayerNorm/LayerNormalization -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSelfOutput

+/encoder/layer.0/attention/output/dense/Add -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSelfOutput

+/encoder/layer.0/attention/output/dense/MatMul -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSelfOutput

+/encoder/layer.0/attention/self/Add -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/Cast -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/Cast_1 -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/Constant -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/Constant_1 -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/Constant_2 -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/Constant_3 -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/Constant_4 -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/Constant_5 -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/Constant_6 -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/Div -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/MatMul -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/MatMul_1 -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/Mul -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/Mul_1 -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/Reshape -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/Reshape_1 -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/Reshape_2 -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/Reshape_3 -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/Shape -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/Slice -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/Softmax -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/Sqrt -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/Sqrt_1 -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/Sqrt_2 -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/Transpose -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/Transpose_1 -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/Transpose_2 -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/Transpose_3 -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/key/Add -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/key/MatMul -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/query/Add -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/query/MatMul -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/value/Add -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/attention/self/value/MatMul -> /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention

+/encoder/layer.0/intermediate/dense/Add -> /BertModel/BertEncoder/BertLayer.0/BertIntermediate

+/encoder/layer.0/intermediate/dense/MatMul -> /BertModel/BertEncoder/BertLayer.0/BertIntermediate

+/encoder/layer.0/intermediate/intermediate_act_fn/Add -> /BertModel/BertEncoder/BertLayer.0/BertIntermediate/GELUActivation

+/encoder/layer.0/intermediate/intermediate_act_fn/Constant -> /BertModel/BertEncoder/BertLayer.0/BertIntermediate/GELUActivation

+/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1 -> /BertModel/BertEncoder/BertLayer.0/BertIntermediate/GELUActivation

+/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2 -> /BertModel/BertEncoder/BertLayer.0/BertIntermediate/GELUActivation

+/encoder/layer.0/intermediate/intermediate_act_fn/Div -> /BertModel/BertEncoder/BertLayer.0/BertIntermediate/GELUActivation

+/encoder/layer.0/intermediate/intermediate_act_fn/Erf -> /BertModel/BertEncoder/BertLayer.0/BertIntermediate/GELUActivation

+/encoder/layer.0/intermediate/intermediate_act_fn/Mul -> /BertModel/BertEncoder/BertLayer.0/BertIntermediate/GELUActivation

+/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1 -> /BertModel/BertEncoder/BertLayer.0/BertIntermediate/GELUActivation

+/encoder/layer.0/output/Add -> /BertModel/BertEncoder/BertLayer.0/BertOutput

+/encoder/layer.0/output/LayerNorm/LayerNormalization -> /BertModel/BertEncoder/BertLayer.0/BertOutput

+/encoder/layer.0/output/dense/Add -> /BertModel/BertEncoder/BertLayer.0/BertOutput

+/encoder/layer.0/output/dense/MatMul -> /BertModel/BertEncoder/BertLayer.0/BertOutput

+/encoder/layer.1/attention/output/Add -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSelfOutput

+/encoder/layer.1/attention/output/LayerNorm/LayerNormalization -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSelfOutput

+/encoder/layer.1/attention/output/dense/Add -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSelfOutput

+/encoder/layer.1/attention/output/dense/MatMul -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSelfOutput

+/encoder/layer.1/attention/self/Add -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/Cast -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/Cast_1 -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/Constant -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/Constant_1 -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/Constant_2 -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/Constant_3 -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/Constant_4 -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/Constant_5 -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/Constant_6 -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/Div -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/MatMul -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/MatMul_1 -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/Mul -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/Mul_1 -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/Reshape -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/Reshape_1 -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/Reshape_2 -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/Reshape_3 -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/Shape -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/Slice -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/Softmax -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/Sqrt -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/Sqrt_1 -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/Sqrt_2 -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/Transpose -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/Transpose_1 -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/Transpose_2 -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/Transpose_3 -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/key/Add -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/key/MatMul -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/query/Add -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/query/MatMul -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/value/Add -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/attention/self/value/MatMul -> /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention

+/encoder/layer.1/intermediate/dense/Add -> /BertModel/BertEncoder/BertLayer.1/BertIntermediate

+/encoder/layer.1/intermediate/dense/MatMul -> /BertModel/BertEncoder/BertLayer.1/BertIntermediate

+/encoder/layer.1/intermediate/intermediate_act_fn/Add -> /BertModel/BertEncoder/BertLayer.1/BertIntermediate/GELUActivation

+/encoder/layer.1/intermediate/intermediate_act_fn/Constant -> /BertModel/BertEncoder/BertLayer.1/BertIntermediate/GELUActivation

+/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1 -> /BertModel/BertEncoder/BertLayer.1/BertIntermediate/GELUActivation

+/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2 -> /BertModel/BertEncoder/BertLayer.1/BertIntermediate/GELUActivation

+/encoder/layer.1/intermediate/intermediate_act_fn/Div -> /BertModel/BertEncoder/BertLayer.1/BertIntermediate/GELUActivation

+/encoder/layer.1/intermediate/intermediate_act_fn/Erf -> /BertModel/BertEncoder/BertLayer.1/BertIntermediate/GELUActivation

+/encoder/layer.1/intermediate/intermediate_act_fn/Mul -> /BertModel/BertEncoder/BertLayer.1/BertIntermediate/GELUActivation

+/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1 -> /BertModel/BertEncoder/BertLayer.1/BertIntermediate/GELUActivation

+/encoder/layer.1/output/Add -> /BertModel/BertEncoder/BertLayer.1/BertOutput

+/encoder/layer.1/output/LayerNorm/LayerNormalization -> /BertModel/BertEncoder/BertLayer.1/BertOutput

+/encoder/layer.1/output/dense/Add -> /BertModel/BertEncoder/BertLayer.1/BertOutput

+/encoder/layer.1/output/dense/MatMul -> /BertModel/BertEncoder/BertLayer.1/BertOutput

+/pooler/Gather -> /BertModel/BertPooler

+/pooler/activation/Tanh -> /BertModel/BertPooler

+/pooler/dense/Gemm -> /BertModel/BertPooler

+

+[2025-07-18T16:16:48Z] tag_injection: Completed

+

+[2025-07-18T16:16:48Z] metadata_generation: Completed

+

+EXPORT SUMMARY

+----------------------------------------

+Total Export Time: 4.42s

+ONNX File Size: 16.76MB

+Final Coverage: 100.0%

+Empty Tags: 0 ✅

 

 ================================================================================

-🔧 STEP 2/8: INPUT GENERATION & VALIDATION

-================================================================================

-🤖 Auto-generating inputs for: prajjwal1/bert-tiny

-   • Model type: bert

-   • Auto-detected task: feature-extraction

-✅ Created onnx export config for bert with task feature-extraction

-🔧 Generated 3 input tensors:

-   • input_ids: [2, 16] (torch.int64)

-   • attention_mask: [2, 16] (torch.int64)

-   • token_type_ids: [2, 16] (torch.int64)

-

-================================================================================

-🏗️ STEP 3/8: HIERARCHY BUILDING

-================================================================================

-✅ Hierarchy building completed with TracingHierarchyBuilder

-📈 Traced 18 modules

-🔄 Execution steps: 36

-

-🌳 Module Hierarchy:

-------------------------------------------------------------

-BertModel

-├── BertEmbeddings: embeddings

-├── BertEncoder: encoder

-│   ├── BertLayer: encoder.layer.0

-│   │   ├── BertAttention: encoder.layer.0.attention

-│   │   │   ├── BertSdpaSelfAttention: encoder.layer.0.attention.self

-│   │   │   └── BertSelfOutput: encoder.layer.0.attention.output

-│   │   ├── BertIntermediate: encoder.layer.0.intermediate

-│   │   │   └── GELUActivation: encoder.layer.0.intermediate.intermediate_act_fn

-│   │   └── BertOutput: encoder.layer.0.output

-│   └── BertLayer: encoder.layer.1

-│       ├── BertAttention: encoder.layer.1.attention

-│       │   ├── BertSdpaSelfAttention: encoder.layer.1.attention.self

-│       │   └── BertSelfOutput: encoder.layer.1.attention.output

-│       ├── BertIntermediate: encoder.layer.1.intermediate

-│       │   └── GELUActivation: encoder.layer.1.intermediate.intermediate_act_fn

-│       └── BertOutput: encoder.layer.1.output

-└── BertPooler: pooler

-

-================================================================================

-📦 STEP 4/8: ONNX EXPORT

-================================================================================

-🎯 Target file: temp/baseline/model.onnx

-⚙️ Export config:

-   • opset_version: 17

-   • do_constant_folding: True

-   • verbose: False

-   • input_names: ['input_ids', 'attention_mask', 'token_type_ids']

-✅ ONNX export completed successfully

-

-================================================================================

-🏷️ STEP 5/8: NODE TAGGER CREATION

-================================================================================

-✅ Node tagger created successfully

-🏷️ Model root tag: /BertModel

-🔧 Operation fallback: disabled

-

-================================================================================

-🔗 STEP 6/8: ONNX NODE TAGGING

-================================================================================

-✅ Node tagging completed successfully

-📈 Coverage: 100.0%

-📊 Tagged nodes: 136/136

-   • Direct matches: 83 (61.0%)

-   • Parent matches: 34 (25.0%)

-   • Root fallbacks: 19 (14.0%)

-✅ Empty tags: 0

-

-📊 Top 20 Nodes by Hierarchy:

-------------------------------

- 1. /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSdpaSelfAttention: 35 nodes

- 2. /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSdpaSelfAttention: 35 nodes

- 3. /BertModel: 19 nodes

- 4. /BertModel/BertEmbeddings: 8 nodes

- 5. /BertModel/BertEncoder/BertLayer.0/BertIntermediate/GELUActivation: 8 nodes

- 6. /BertModel/BertEncoder/BertLayer.1/BertIntermediate/GELUActivation: 8 nodes

- 7. /BertModel/BertEncoder/BertLayer.0/BertAttention/BertSelfOutput: 4 nodes

- 8. /BertModel/BertEncoder/BertLayer.0/BertOutput: 4 nodes

- 9. /BertModel/BertEncoder/BertLayer.1/BertAttention/BertSelfOutput: 4 nodes

-10. /BertModel/BertEncoder/BertLayer.1/BertOutput: 4 nodes

-11. /BertModel/BertPooler: 3 nodes

-12. /BertModel/BertEncoder/BertLayer.0/BertIntermediate: 2 nodes

-13. /BertModel/BertEncoder/BertLayer.1/BertIntermediate: 2 nodes

-

-🌳 Complete HF Hierarchy with ONNX Nodes:

-------------------------------------------------------------

-BertModel (136 ONNX nodes)

-├── BertEmbeddings: embeddings (8 nodes)

-│   ├── Add (2 ops)

-│   ├── Constant (2 ops)

-│   ├── Gather (3 ops)

-│   └── LayerNormalization: /embeddings/LayerNorm/LayerNormalization

-├── BertEncoder: encoder (106 nodes)

-│   ├── BertLayer: encoder.layer.0 (53 nodes)

-│   │   ├── BertAttention: encoder.layer.0.attention (39 nodes)

-│   │   │   ├── BertSdpaSelfAttention: encoder.layer.0.attention.self (35 nodes)

-│   │   │   │   ├── Add (4 ops)

-│   │   │   │   ├── Cast (2 ops)

-│   │   │   │   ├── Constant (7 ops)

-│   │   │   │   ├── Div: /encoder/layer.0/attention/self/Div

-│   │   │   │   ├── MatMul (5 ops)

-│   │   │   │   ├── Mul (2 ops)

-│   │   │   │   ├── Reshape (4 ops)

-│   │   │   │   ├── Shape: /encoder/layer.0/attention/self/Shape

-│   │   │   │   ├── Slice: /encoder/layer.0/attention/self/Slice

-│   │   │   │   ├── Softmax: /encoder/layer.0/attention/self/Softmax

-│   │   │   │   ├── Sqrt (3 ops)

-│   │   │   │   └── Transpose (4 ops)

-│   │   │   └── BertSelfOutput: encoder.layer.0.attention.output (4 nodes)

-│   │   │       ├── Add (2 ops)

-│   │   │       ├── LayerNormalization: 

-│   │   │       │   /encoder/layer.0/attention/output/LayerNorm/LayerNormalizati

-│   │   │       │   on

-│   │   │       └── MatMul: /encoder/layer.0/attention/output/dense/MatMul

-│   │   ├── BertIntermediate: encoder.layer.0.intermediate (10 nodes)

-│   │   │   ├── Add: /encoder/layer.0/intermediate/dense/Add

-... and 53 more lines (truncated for console)

-(showing 30/83 lines)

-

-================================================================================

-🏷️ STEP 7/8: TAG INJECTION

-================================================================================

-🏷️ Hierarchy tag attributes: enabled

-✅ Tags injected into ONNX model successfully

-📄 Updated ONNX file: temp/baseline/model.onnx

-

-================================================================================

-📄 STEP 8/8: METADATA GENERATION

-================================================================================

-✅ Metadata file created successfully

-📄 Metadata file: temp/baseline/model_htp_metadata.json

-

-================================================================================

-📋 FINAL EXPORT SUMMARY

-================================================================================

-🎉 HTP Export completed successfully in 4.83s!

-📊 Export Statistics:

-   • Export time: 4.83s

-   • Hierarchy modules: 18

-   • ONNX nodes: 136

-   • Tagged nodes: 136

-   • Coverage: 100.0%

-   • Empty tags: 0 ✅

-

-📁 Output Files:

-   • ONNX model: temp/baseline/model.onnx

-   • Metadata: temp/baseline/model_htp_metadata.json

-   • Report: temp/baseline/model_htp_export_report.txt

-

+Export completed successfully!
