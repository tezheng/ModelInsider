{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TorchScript Intermediate State Exploration\n",
    "\n",
    "This notebook explores what information is available in TorchScript graph before ONNX conversion,\n",
    "specifically investigating the scope information that contains module hierarchy.\n",
    "\n",
    "## Key Research Questions:\n",
    "1. What scope information is available at the TorchScript level?\n",
    "2. How can we access `node.scopeName()` properly?\n",
    "3. Where exactly is context lost during ONNX conversion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import json\n",
    "from typing import Dict, List, Any\n",
    "import os\n",
    "\n",
    "# Create temp directory for outputs\n",
    "os.makedirs(\"../temp\", exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Model and Prepare Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a small model for exploration\n",
    "model_name = \"prajjwal1/bert-tiny\"\n",
    "print(f\"Loading model: {model_name}\")\n",
    "\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Prepare inputs\n",
    "text = \"Hello world\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# Set model to eval mode\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model type: {type(model).__name__}\")\n",
    "print(f\"Input shapes: {[(k, v.shape) for k, v in inputs.items()]}\")\n",
    "print(\"‚úÖ Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Attempt Different Tracing Approaches\n",
    "\n",
    "We'll try multiple methods to trace the model and see which one preserves scope information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try multiple tracing approaches\n",
    "traced_model = None\n",
    "tracing_method = None\n",
    "\n",
    "print(\"Trying different tracing approaches...\\n\")\n",
    "\n",
    "# Approach 1: Direct tracing with strict=False (to handle dict output)\n",
    "try:\n",
    "    print(\"1. Trying direct tracing with strict=False...\")\n",
    "    with torch.no_grad():\n",
    "        traced_model = torch.jit.trace(\n",
    "            model, \n",
    "            inputs, \n",
    "            strict=False,\n",
    "            check_trace=False\n",
    "        )\n",
    "    print(\"  ‚úÖ Direct tracing successful\")\n",
    "    tracing_method = \"direct_trace\"\n",
    "except Exception as e:\n",
    "    print(f\"  ‚ùå Direct tracing failed: {e}\")\n",
    "    \n",
    "    # Approach 2: Try with positional args\n",
    "    try:\n",
    "        print(\"\\n2. Trying positional args tracing...\")\n",
    "        with torch.no_grad():\n",
    "            traced_model = torch.jit.trace(\n",
    "                model, \n",
    "                (inputs['input_ids'], inputs['attention_mask']),\n",
    "                strict=False,\n",
    "                check_trace=False\n",
    "            )\n",
    "        print(\"  ‚úÖ Positional args tracing successful\")\n",
    "        tracing_method = \"positional_trace\"\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Positional args tracing failed: {e}\")\n",
    "        \n",
    "        # Approach 3: Wrapper approach\n",
    "        print(\"\\n3. Using wrapper as fallback...\")\n",
    "        class ModelWrapper(nn.Module):\n",
    "            def __init__(self, model):\n",
    "                super().__init__()\n",
    "                self.model = model\n",
    "            \n",
    "            def forward(self, input_ids, attention_mask):\n",
    "                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                return outputs.last_hidden_state\n",
    "        \n",
    "        wrapped_model = ModelWrapper(model)\n",
    "        with torch.no_grad():\n",
    "            traced_model = torch.jit.trace(wrapped_model, (inputs['input_ids'], inputs['attention_mask']))\n",
    "        print(\"  ‚úÖ Wrapper tracing successful\")\n",
    "        tracing_method = \"wrapper_trace\"\n",
    "\n",
    "print(f\"\\nüéØ Using tracing method: {tracing_method}\")\n",
    "print(f\"Traced model type: {type(traced_model)}\")\n",
    "print(f\"Has graph: {hasattr(traced_model, 'graph')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Access TorchScript Graph and Explore Node Information\n",
    "\n",
    "Now let's examine the graph structure and try to extract scope information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the TorchScript graph\n",
    "print(\"Accessing TorchScript graph...\\n\")\n",
    "graph = traced_model.graph\n",
    "nodes = list(graph.nodes())\n",
    "\n",
    "print(f\"Total nodes in graph: {len(nodes)}\")\n",
    "print(f\"Graph type: {type(graph)}\")\n",
    "\n",
    "# Show graph string representation (this might contain scope info)\n",
    "print(\"\\n=== Graph String Representation (first 2000 chars) ===\")\n",
    "graph_str = str(graph)\n",
    "print(graph_str[:2000])\n",
    "if len(graph_str) > 2000:\n",
    "    print(f\"... (truncated, total length: {len(graph_str)} chars)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Deep Node Analysis\n",
    "\n",
    "Let's examine individual nodes and try different methods to extract scope information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore node information in detail\n",
    "print(\"Exploring node information...\\n\")\n",
    "\n",
    "node_info = []\n",
    "scope_hierarchy = set()\n",
    "\n",
    "for i, node in enumerate(nodes[:10]):  # First 10 nodes for detailed analysis\n",
    "    try:\n",
    "        print(f\"=== Node {i} ===\")\n",
    "        \n",
    "        # Basic node information\n",
    "        info = {\n",
    "            \"index\": i,\n",
    "            \"kind\": str(node.kind()),\n",
    "            \"has_scope\": hasattr(node, 'scopeName'),\n",
    "        }\n",
    "        \n",
    "        # Try different ways to get scope information\n",
    "        scope_methods = {\n",
    "            \"scopeName()\": lambda n: str(n.scopeName()) if hasattr(n, 'scopeName') else \"No method\",\n",
    "            \"scope()\": lambda n: str(n.scope()) if hasattr(n, 'scope') else \"No method\", \n",
    "            \"sourceRange()\": lambda n: str(n.sourceRange()) if hasattr(n, 'sourceRange') else \"No method\",\n",
    "            \"debugName()\": lambda n: str(n.debugName()) if hasattr(n, 'debugName') else \"No method\",\n",
    "        }\n",
    "        \n",
    "        for method_name, method_func in scope_methods.items():\n",
    "            try:\n",
    "                result = method_func(node)\n",
    "                info[method_name] = result\n",
    "                print(f\"  {method_name}: {result}\")\n",
    "            except Exception as e:\n",
    "                info[method_name] = f\"Error: {e}\"\n",
    "                print(f\"  {method_name}: Error - {e}\")\n",
    "        \n",
    "        # Try to get all available methods/attributes\n",
    "        available_methods = [attr for attr in dir(node) if not attr.startswith('_')]\n",
    "        info[\"available_methods\"] = available_methods[:10]  # First 10 to avoid clutter\n",
    "        \n",
    "        print(f\"  Available methods (first 10): {info['available_methods']}\")\n",
    "        \n",
    "        node_info.append(info)\n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing node {i}: {e}\")\n",
    "        node_info.append({\"index\": i, \"error\": str(e)})\n",
    "\n",
    "print(f\"‚úÖ Analyzed {len(node_info)} nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Try to Access the Full Graph IR\n",
    "\n",
    "The error message we saw earlier contained rich scope information. Let's try to access that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to access the full IR graph\n",
    "print(\"Trying to access detailed graph representation...\\n\")\n",
    "\n",
    "# Method 1: Get the inlined graph (this might have scope info)\n",
    "try:\n",
    "    if hasattr(traced_model, 'inlined_graph'):\n",
    "        inlined_graph = traced_model.inlined_graph\n",
    "        print(f\"Found inlined_graph: {type(inlined_graph)}\")\n",
    "        \n",
    "        inlined_nodes = list(inlined_graph.nodes())\n",
    "        print(f\"Inlined graph has {len(inlined_nodes)} nodes\")\n",
    "        \n",
    "        # Check first few nodes for scope info\n",
    "        for i, node in enumerate(inlined_nodes[:5]):\n",
    "            scope_name = str(node.scopeName()) if hasattr(node, 'scopeName') else \"No scope\"\n",
    "            print(f\"  Inlined Node {i}: {node.kind()} - Scope: {scope_name}\")\n",
    "    else:\n",
    "        print(\"No inlined_graph attribute found\")\n",
    "except Exception as e:\n",
    "    print(f\"Error accessing inlined_graph: {e}\")\n",
    "\n",
    "# Method 2: Try to trigger an ONNX export to see the detailed IR in the error\n",
    "print(\"\\n--- Attempting ONNX export to reveal detailed IR ---\")\n",
    "try:\n",
    "    onnx_file = \"../temp/debug_onnx_export.onnx\"\n",
    "    \n",
    "    if tracing_method == \"positional_trace\":\n",
    "        torch.onnx.export(\n",
    "            traced_model,\n",
    "            (inputs['input_ids'], inputs['attention_mask']),\n",
    "            onnx_file,\n",
    "            input_names=['input_ids', 'attention_mask'],\n",
    "            output_names=['output'],\n",
    "            do_constant_folding=False,  # Keep constants separate\n",
    "            verbose=True\n",
    "        )\n",
    "        print(\"‚úÖ ONNX export successful (unexpectedly!)\")\n",
    "    else:\n",
    "        print(\"Skipping ONNX export for wrapper method (would fail)\")\n",
    "        \n",
    "except Exception as e:\n",
    "    error_str = str(e)\n",
    "    print(f\"ONNX export failed as expected. Analyzing error for scope info...\")\n",
    "    \n",
    "    # Look for scope information in the error message\n",
    "    if \"scope:\" in error_str:\n",
    "        print(\"\\nüéØ FOUND SCOPE INFORMATION IN ERROR!\")\n",
    "        \n",
    "        # Extract lines containing scope information\n",
    "        scope_lines = [line.strip() for line in error_str.split('\\n') if 'scope:' in line]\n",
    "        \n",
    "        print(f\"Found {len(scope_lines)} lines with scope information:\")\n",
    "        for i, line in enumerate(scope_lines[:10]):  # Show first 10\n",
    "            print(f\"  {i+1}. {line}\")\n",
    "        \n",
    "        if len(scope_lines) > 10:\n",
    "            print(f\"  ... and {len(scope_lines) - 10} more\")\n",
    "            \n",
    "        # Extract unique scopes\n",
    "        unique_scopes = set()\n",
    "        for line in scope_lines:\n",
    "            if 'scope:' in line:\n",
    "                scope_part = line.split('scope:')[1].split('#')[0].strip()\n",
    "                unique_scopes.add(scope_part)\n",
    "        \n",
    "        print(f\"\\nüéØ Unique scopes found: {len(unique_scopes)}\")\n",
    "        for scope in sorted(list(unique_scopes))[:15]:  # Show first 15\n",
    "            print(f\"  {scope}\")\n",
    "    else:\n",
    "        print(\"No scope information found in error message.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Alternative Approach: torch.fx Tracing\n",
    "\n",
    "Let's try torch.fx which might preserve more context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trying torch.fx symbolic tracing...\\n\")\n",
    "\n",
    "try:\n",
    "    import torch.fx as fx\n",
    "    \n",
    "    # Try to symbolically trace the model\n",
    "    print(\"1. Attempting symbolic tracing...\")\n",
    "    \n",
    "    # This might fail for transformers models, but let's try\n",
    "    try:\n",
    "        fx_traced = fx.symbolic_trace(model)\n",
    "        print(\"  ‚úÖ Symbolic tracing successful!\")\n",
    "        \n",
    "        # Explore FX graph\n",
    "        fx_graph = fx_traced.graph\n",
    "        fx_nodes = list(fx_graph.nodes)\n",
    "        \n",
    "        print(f\"  FX graph has {len(fx_nodes)} nodes\")\n",
    "        \n",
    "        # Show first few nodes\n",
    "        for i, node in enumerate(fx_nodes[:10]):\n",
    "            print(f\"    Node {i}: {node.op} - {node.target} - {node.name}\")\n",
    "            if hasattr(node, 'meta') and node.meta:\n",
    "                print(f\"      Meta: {node.meta}\")\n",
    "                \n",
    "        # Try torch.export (PyTorch 2.0+)\n",
    "        print(\"\\n2. Attempting torch.export...\")\n",
    "        try:\n",
    "            exported_program = torch.export.export(model, (inputs['input_ids'], inputs['attention_mask']))\n",
    "            print(\"  ‚úÖ torch.export successful!\")\n",
    "            \n",
    "            export_graph = exported_program.module.graph\n",
    "            export_nodes = list(export_graph.nodes)\n",
    "            \n",
    "            print(f\"  Export graph has {len(export_nodes)} nodes\")\n",
    "            \n",
    "            # Show first few nodes with metadata\n",
    "            for i, node in enumerate(export_nodes[:5]):\n",
    "                print(f\"    Export Node {i}: {node.op} - {node.target}\")\n",
    "                if hasattr(node, 'meta') and node.meta:\n",
    "                    print(f\"      Meta keys: {list(node.meta.keys())}\")\n",
    "                    if 'stack_trace' in node.meta:\n",
    "                        print(f\"      Stack trace available: {len(node.meta['stack_trace'])} frames\")\n",
    "                        \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå torch.export failed: {e}\")\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Symbolic tracing failed: {e}\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"torch.fx not available in this PyTorch version\")\n",
    "except Exception as e:\n",
    "    print(f\"Error with torch.fx: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Results and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save detailed results\n",
    "results = {\n",
    "    \"model_name\": model_name,\n",
    "    \"tracing_method\": tracing_method,\n",
    "    \"total_nodes\": len(nodes),\n",
    "    \"graph_string_length\": len(str(graph)),\n",
    "    \"node_analysis\": node_info,\n",
    "    \"exploration_summary\": {\n",
    "        \"torch_jit_scope_available\": any(info.get(\"scopeName()\", \"\") != \"\" for info in node_info),\n",
    "        \"methods_attempted\": list(scope_methods.keys()) if 'scope_methods' in locals() else [],\n",
    "        \"graph_string_contains_scope\": \"scope:\" in str(graph),\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "output_file = \"../temp/torchscript_exploration_notebook.json\"\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Results saved to: {output_file}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPLORATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Tracing method: {tracing_method}\")\n",
    "print(f\"Total TorchScript nodes: {len(nodes)}\")\n",
    "print(f\"Graph string length: {len(str(graph))} chars\")\n",
    "print(f\"Contains 'scope:' in graph string: {'scope:' in str(graph)}\")\n",
    "\n",
    "scope_available = any(info.get(\"scopeName()\", \"\") not in [\"\", \"No method\"] for info in node_info)\n",
    "print(f\"Scope information accessible via scopeName(): {scope_available}\")\n",
    "\n",
    "print(\"\\nüéØ KEY FINDINGS:\")\n",
    "if \"scope:\" in str(graph):\n",
    "    print(\"‚úÖ Scope information IS present in the graph string representation\")\n",
    "    print(\"‚úÖ We can extract module hierarchy from TorchScript before ONNX export\")\n",
    "else:\n",
    "    print(\"‚ùå No scope information found in graph representation\")\n",
    "    \n",
    "if scope_available:\n",
    "    print(\"‚úÖ Individual node scope access working\")\n",
    "else:\n",
    "    print(\"‚ùå Individual node scopeName() not working - need alternative approach\")\n",
    "\n",
    "print(\"\\nüí° NEXT STEPS:\")\n",
    "print(\"1. Parse graph string representation to extract scope information\")\n",
    "print(\"2. Implement JIT graph interception before ONNX conversion\")\n",
    "print(\"3. Create hierarchy mapping from TorchScript to ONNX nodes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}