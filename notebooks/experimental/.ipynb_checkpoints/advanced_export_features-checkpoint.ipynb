{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Model Export Features Demo\n",
    "\n",
    "This notebook demonstrates the new advanced export features:\n",
    "1. **JIT Graph Dumping** - Extract module hierarchy before ONNX conversion\n",
    "2. **FX Graph Export** - Alternative representation (dynamo=False)\n",
    "3. **Comprehensive Analysis** - Compare different export methods\n",
    "\n",
    "## Key Research Findings\n",
    "- ‚úÖ **Context preservation**: Module hierarchy IS available in TorchScript graphs\n",
    "- ‚úÖ **Interception point**: We can capture scope info before ONNX conversion\n",
    "- ‚úÖ **Multiple alternatives**: FX graphs provide different perspectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Setup\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "os.makedirs('../temp/notebook_exports', exist_ok=True)\n",
    "\n",
    "print(\"üìö Notebook setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Full Feature Export\n",
    "\n",
    "Let's run the complete export with all new features enabled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the full export with all features\n",
    "cmd = [\n",
    "    \"uv\", \"run\", \"modelexport\", \"--verbose\", \"export\",\n",
    "    \"prajjwal1/bert-tiny\", \n",
    "    \"../temp/notebook_exports/bert_full_demo.onnx\",\n",
    "    \"--config\", \"../export_config_bertmodel.json\",\n",
    "    \"--jit-graph\",\n",
    "    \"--fx-graph\", \"both\",\n",
    "    \"--strategy\", \"htp\"\n",
    "]\n",
    "\n",
    "print(\"üöÄ Running full export with all advanced features...\")\n",
    "print(f\"Command: {' '.join(cmd)}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "result = subprocess.run(cmd, capture_output=True, text=True, cwd=\"..\")\n",
    "\n",
    "print(\"STDOUT:\")\n",
    "print(result.stdout)\n",
    "\n",
    "if result.stderr:\n",
    "    print(\"\\nSTDERR:\")\n",
    "    print(result.stderr)\n",
    "\n",
    "print(f\"\\n‚úÖ Export completed with return code: {result.returncode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. JIT Graph Analysis\n",
    "\n",
    "Let's analyze the captured TorchScript graph information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JIT graph information\n",
    "jit_info_path = \"../temp/notebook_exports/bert_full_demo_jit_debug/jit_graph_info.json\"\n",
    "\n",
    "if Path(jit_info_path).exists():\n",
    "    with open(jit_info_path, 'r') as f:\n",
    "        jit_data = json.load(f)\n",
    "    \n",
    "    print(\"üîç JIT GRAPH ANALYSIS RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Basic statistics\n",
    "    graph_info = jit_data['graph_info']\n",
    "    scope_stats = jit_data['scope_statistics']\n",
    "    \n",
    "    print(f\"üìä Graph Statistics:\")\n",
    "    print(f\"   Total nodes: {graph_info['total_nodes']}\")\n",
    "    print(f\"   Graph string length: {graph_info['graph_string_length']:,} chars\")\n",
    "    print(f\"   Extraction success: {scope_stats['extraction_success']}\")\n",
    "    print(f\"   Total scopes found: {scope_stats['total_scopes']}\")\n",
    "    \n",
    "    # Scope hierarchy analysis\n",
    "    hierarchy = jit_data['unified_scope_hierarchy']\n",
    "    print(f\"\\nüå≥ Scope Hierarchy:\")\n",
    "    print(f\"   Unique scopes: {hierarchy['total_unique_scopes']}\")\n",
    "    \n",
    "    # Show module-specific scopes (not execution paths)\n",
    "    module_scopes = [s for s in hierarchy['scope_list'] if '__module' in s]\n",
    "    print(f\"\\nüéØ Module Scopes Found ({len(module_scopes)}):\")\n",
    "    for i, scope in enumerate(module_scopes, 1):\n",
    "        print(f\"   {i:2d}. {scope}\")\n",
    "    \n",
    "    # Coverage analysis\n",
    "    if 'coverage_analysis' in scope_stats:\n",
    "        coverage = scope_stats['coverage_analysis']\n",
    "        print(f\"\\nüìà Coverage Analysis:\")\n",
    "        print(f\"   BERT modules: {'‚úÖ' if coverage['has_bert_modules'] else '‚ùå'}\")\n",
    "        print(f\"   Attention modules: {'‚úÖ' if coverage['has_attention_modules'] else '‚ùå'}\")\n",
    "        print(f\"   Layer modules: {'‚úÖ' if coverage['has_layer_modules'] else '‚ùå'}\")\n",
    "        print(f\"   Unique module types: {coverage['unique_module_types']}\")\n",
    "    \n",
    "    # Depth analysis visualization\n",
    "    if 'scope_analysis' in hierarchy:\n",
    "        depth_dist = hierarchy['scope_analysis']['depth_distribution']\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Convert string keys to integers for proper sorting\n",
    "        depths = [int(k) for k in depth_dist.keys()]\n",
    "        counts = [depth_dist[str(d)] for d in depths]\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.bar(depths, counts, alpha=0.7, color='skyblue')\n",
    "        plt.xlabel('Scope Depth')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Scope Depth Distribution')\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Module types\n",
    "        module_types = hierarchy['scope_analysis']['module_types']\n",
    "        if module_types:\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.pie([1] * len(module_types), labels=module_types[:8], autopct='', startangle=90)\n",
    "            plt.title(f'Module Types Found ({len(module_types)} total)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå JIT graph information not found. Export may have failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. FX Graph Analysis\n",
    "\n",
    "Let's examine the FX graph export results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FX graph information\n",
    "fx_info_path = \"../temp/notebook_exports/bert_full_demo_fx_graph.json\"\n",
    "\n",
    "if Path(fx_info_path).exists():\n",
    "    with open(fx_info_path, 'r') as f:\n",
    "        fx_data = json.load(f)\n",
    "    \n",
    "    print(\"üîß FX GRAPH ANALYSIS RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Check which methods succeeded\n",
    "    methods_tried = []\n",
    "    successful_methods = []\n",
    "    \n",
    "    if 'symbolic_trace_results' in fx_data:\n",
    "        methods_tried.append('symbolic_trace')\n",
    "        if fx_data['symbolic_trace_results'].get('success'):\n",
    "            successful_methods.append('symbolic_trace')\n",
    "    \n",
    "    if 'torch_export_results' in fx_data:\n",
    "        methods_tried.append('torch_export')\n",
    "        if fx_data['torch_export_results'].get('success'):\n",
    "            successful_methods.append('torch_export')\n",
    "    \n",
    "    # If single method was used\n",
    "    if 'method' in fx_data:\n",
    "        methods_tried = [fx_data['method']]\n",
    "        if fx_data.get('success'):\n",
    "            successful_methods = [fx_data['method']]\n",
    "    \n",
    "    print(f\"üìä FX Export Summary:\")\n",
    "    print(f\"   Methods tried: {', '.join(methods_tried)}\")\n",
    "    print(f\"   Successful methods: {', '.join(successful_methods) if successful_methods else 'None'}\")\n",
    "    print(f\"   Overall success: {'‚úÖ' if fx_data.get('success') or successful_methods else '‚ùå'}\")\n",
    "    \n",
    "    # Analyze successful exports\n",
    "    for method in successful_methods:\n",
    "        if method in fx_data:\n",
    "            method_data = fx_data[method]\n",
    "        elif f'{method}_results' in fx_data:\n",
    "            method_data = fx_data[f'{method}_results']\n",
    "        else:\n",
    "            method_data = fx_data\n",
    "        \n",
    "        print(f\"\\nüéØ {method.upper()} Results:\")\n",
    "        print(f\"   Success: {method_data.get('success', False)}\")\n",
    "        print(f\"   Execution test: {method_data.get('execution_test', 'unknown')}\")\n",
    "        \n",
    "        if 'fx_graph_analysis' in method_data:\n",
    "            analysis = method_data['fx_graph_analysis']\n",
    "            print(f\"   Total nodes: {analysis.get('total_nodes', 'unknown')}\")\n",
    "            print(f\"   Node types: {len(analysis.get('node_types', {}))}\")\n",
    "            print(f\"   Nodes with metadata: {analysis.get('nodes_with_meta', 0)}\")\n",
    "            \n",
    "            # Visualize node types if available\n",
    "            if 'node_types' in analysis and analysis['node_types']:\n",
    "                node_types = analysis['node_types']\n",
    "                \n",
    "                plt.figure(figsize=(12, 5))\n",
    "                \n",
    "                plt.subplot(1, 2, 1)\n",
    "                types = list(node_types.keys())\n",
    "                counts = list(node_types.values())\n",
    "                \n",
    "                plt.bar(types, counts, alpha=0.7, color='lightcoral')\n",
    "                plt.xlabel('Node Operation Type')\n",
    "                plt.ylabel('Count')\n",
    "                plt.title(f'{method}: Node Type Distribution')\n",
    "                plt.xticks(rotation=45)\n",
    "                plt.grid(axis='y', alpha=0.3)\n",
    "                \n",
    "                # Sample nodes info\n",
    "                if 'sample_nodes' in analysis:\n",
    "                    sample_nodes = analysis['sample_nodes']\n",
    "                    \n",
    "                    plt.subplot(1, 2, 2)\n",
    "                    meta_counts = [1 if node.get('has_meta') else 0 for node in sample_nodes]\n",
    "                    \n",
    "                    plt.pie([sum(meta_counts), len(meta_counts) - sum(meta_counts)], \n",
    "                           labels=['With Metadata', 'Without Metadata'], \n",
    "                           autopct='%1.1f%%', startangle=90)\n",
    "                    plt.title('Sample Nodes: Metadata Coverage')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "        \n",
    "        # Show code preview if available\n",
    "        if 'graph_code_preview' in method_data:\n",
    "            print(f\"\\nüìÑ {method.upper()} Code Preview:\")\n",
    "            print(\"```python\")\n",
    "            print(method_data['graph_code_preview'])\n",
    "            print(\"```\")\n",
    "    \n",
    "    # Show errors for failed methods\n",
    "    failed_methods = set(methods_tried) - set(successful_methods)\n",
    "    for method in failed_methods:\n",
    "        if method in fx_data:\n",
    "            method_data = fx_data[method]\n",
    "        elif f'{method}_results' in fx_data:\n",
    "            method_data = fx_data[f'{method}_results']\n",
    "        else:\n",
    "            method_data = fx_data\n",
    "        \n",
    "        error = method_data.get('error', 'Unknown error')\n",
    "        print(f\"\\n‚ùå {method.upper()} Failed:\")\n",
    "        print(f\"   Error: {error}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå FX graph information not found. Export may have failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ONNX Export Analysis\n",
    "\n",
    "Let's analyze the standard ONNX export results and compare with our new methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ONNX hierarchy information\n",
    "onnx_hierarchy_path = \"../temp/notebook_exports/bert_full_demo_hierarchy.json\"\n",
    "\n",
    "if Path(onnx_hierarchy_path).exists():\n",
    "    with open(onnx_hierarchy_path, 'r') as f:\n",
    "        onnx_data = json.load(f)\n",
    "    \n",
    "    print(\"üéØ ONNX EXPORT ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Basic export info\n",
    "    summary = onnx_data['summary']\n",
    "    exporter_info = onnx_data['exporter']\n",
    "    \n",
    "    print(f\"üìä Export Summary:\")\n",
    "    print(f\"   Strategy: {exporter_info['strategy']}\")\n",
    "    print(f\"   Total operations: {summary['total_operations']}\")\n",
    "    print(f\"   Tagged operations: {summary['tagged_operations']}\")\n",
    "    print(f\"   Coverage: {summary['tagged_operations']/summary['total_operations']*100:.1f}%\")\n",
    "    print(f\"   Unique tags: {summary['unique_tags']}\")\n",
    "    print(f\"   Operation trace length: {summary['operation_trace_length']}\")\n",
    "    \n",
    "    # Tag distribution analysis\n",
    "    tag_stats = onnx_data['tag_statistics']\n",
    "    \n",
    "    print(f\"\\nüè∑Ô∏è Tag Distribution:\")\n",
    "    sorted_tags = sorted(tag_stats.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for tag, count in sorted_tags[:10]:  # Top 10\n",
    "        print(f\"   {tag}: {count} ops\")\n",
    "    \n",
    "    if len(sorted_tags) > 10:\n",
    "        print(f\"   ... and {len(sorted_tags) - 10} more tags\")\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Tag distribution pie chart\n",
    "    plt.subplot(2, 2, 1)\n",
    "    top_tags = dict(sorted_tags[:8])\n",
    "    other_count = sum(count for _, count in sorted_tags[8:])\n",
    "    if other_count > 0:\n",
    "        top_tags['Others'] = other_count\n",
    "    \n",
    "    plt.pie(top_tags.values(), labels=[t.split('/')[-1] for t in top_tags.keys()], \n",
    "           autopct='%1.1f%%', startangle=90)\n",
    "    plt.title('Operation Distribution by Module')\n",
    "    \n",
    "    # Coverage comparison\n",
    "    plt.subplot(2, 2, 2)\n",
    "    coverage_data = {\n",
    "        'Tagged': summary['tagged_operations'],\n",
    "        'Untagged': summary['total_operations'] - summary['tagged_operations']\n",
    "    }\n",
    "    plt.bar(coverage_data.keys(), coverage_data.values(), \n",
    "           color=['lightgreen', 'lightcoral'], alpha=0.7)\n",
    "    plt.title('Operation Coverage')\n",
    "    plt.ylabel('Number of Operations')\n",
    "    \n",
    "    # Tag hierarchy depth\n",
    "    plt.subplot(2, 2, 3)\n",
    "    tag_depths = [tag.count('/') for tag in tag_stats.keys()]\n",
    "    plt.hist(tag_depths, bins=range(max(tag_depths)+2), alpha=0.7, color='orange')\n",
    "    plt.xlabel('Hierarchy Depth')\n",
    "    plt.ylabel('Number of Tags')\n",
    "    plt.title('Tag Hierarchy Depth Distribution')\n",
    "    \n",
    "    # Module type analysis\n",
    "    plt.subplot(2, 2, 4)\n",
    "    module_types = {}\n",
    "    for tag in tag_stats.keys():\n",
    "        if '/' in tag:\n",
    "            module_type = tag.split('/')[-1]\n",
    "            module_types[module_type] = module_types.get(module_type, 0) + tag_stats[tag]\n",
    "    \n",
    "    if module_types:\n",
    "        sorted_modules = sorted(module_types.items(), key=lambda x: x[1], reverse=True)[:8]\n",
    "        modules, counts = zip(*sorted_modules)\n",
    "        \n",
    "        plt.bar(modules, counts, alpha=0.7, color='lightblue')\n",
    "        plt.xlabel('Module Type')\n",
    "        plt.ylabel('Operations')\n",
    "        plt.title('Operations by Module Type')\n",
    "        plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå ONNX hierarchy information not found. Export may have failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparative Analysis\n",
    "\n",
    "Let's compare the information captured by different methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî¨ COMPARATIVE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_data = []\n",
    "\n",
    "# ONNX Export Analysis\n",
    "if 'onnx_data' in locals():\n",
    "    comparison_data.append({\n",
    "        'Method': 'ONNX Export',\n",
    "        'Success': '‚úÖ',\n",
    "        'Node Count': onnx_data['summary']['total_operations'],\n",
    "        'Tagged Count': onnx_data['summary']['tagged_operations'],\n",
    "        'Unique Tags': onnx_data['summary']['unique_tags'],\n",
    "        'Coverage %': f\"{onnx_data['summary']['tagged_operations']/onnx_data['summary']['total_operations']*100:.1f}%\",\n",
    "        'Key Feature': 'Hierarchy preservation in production format',\n",
    "        'Context Preserved': 'Partial (via tagging)'\n",
    "    })\n",
    "\n",
    "# JIT Graph Analysis\n",
    "if 'jit_data' in locals():\n",
    "    comparison_data.append({\n",
    "        'Method': 'JIT Graph',\n",
    "        'Success': '‚úÖ' if jit_data['scope_statistics']['extraction_success'] else '‚ùå',\n",
    "        'Node Count': jit_data['graph_info']['total_nodes'],\n",
    "        'Tagged Count': '-',\n",
    "        'Unique Tags': jit_data['scope_statistics']['total_scopes'],\n",
    "        'Coverage %': 'N/A',\n",
    "        'Key Feature': 'Pre-ONNX module hierarchy capture',\n",
    "        'Context Preserved': 'Full (before conversion)'\n",
    "    })\n",
    "\n",
    "# FX Graph Analysis\n",
    "if 'fx_data' in locals():\n",
    "    fx_success = fx_data.get('success', False) or len(successful_methods) > 0 if 'successful_methods' in locals() else False\n",
    "    fx_node_count = 'Unknown'\n",
    "    fx_feature = 'Graph representation analysis'\n",
    "    \n",
    "    # Try to get node count from successful method\n",
    "    if 'successful_methods' in locals() and successful_methods:\n",
    "        method = successful_methods[0]\n",
    "        if f'{method}_results' in fx_data and 'fx_graph_analysis' in fx_data[f'{method}_results']:\n",
    "            fx_node_count = fx_data[f'{method}_results']['fx_graph_analysis'].get('total_nodes', 'Unknown')\n",
    "            fx_feature = f'{method.title()} graph representation'\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'Method': 'FX Graph',\n",
    "        'Success': '‚úÖ' if fx_success else '‚ùå',\n",
    "        'Node Count': fx_node_count,\n",
    "        'Tagged Count': '-',\n",
    "        'Unique Tags': '-',\n",
    "        'Coverage %': 'N/A',\n",
    "        'Key Feature': fx_feature,\n",
    "        'Context Preserved': 'Alternative (metadata-based)'\n",
    "    })\n",
    "\n",
    "# Display comparison table\n",
    "if comparison_data:\n",
    "    df = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    print(\"üìä Method Comparison:\")\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    # Success rate visualization\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    success_counts = df['Success'].value_counts()\n",
    "    plt.pie(success_counts.values, labels=success_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "    plt.title('Export Method Success Rate')\n",
    "    \n",
    "    # Node count comparison (where available)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    node_data = []\n",
    "    labels = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        if row['Node Count'] != '-' and str(row['Node Count']).isdigit():\n",
    "            node_data.append(int(row['Node Count']))\n",
    "            labels.append(row['Method'])\n",
    "    \n",
    "    if node_data:\n",
    "        plt.bar(labels, node_data, alpha=0.7, color=['skyblue', 'lightgreen', 'orange'])\n",
    "        plt.ylabel('Node Count')\n",
    "        plt.title('Graph Size Comparison')\n",
    "        plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nüéØ KEY INSIGHTS:\")\n",
    "print(\"1. ‚úÖ JIT graphs preserve FULL module context before ONNX conversion\")\n",
    "print(\"2. ‚úÖ ONNX export achieves high coverage with hierarchy tagging\")\n",
    "print(\"3. ‚ö†Ô∏è  FX graphs may face compatibility issues with complex models\")\n",
    "print(\"4. üöÄ Combined approach provides comprehensive model analysis\")\n",
    "\n",
    "print(\"\\nüí° RECOMMENDED WORKFLOW:\")\n",
    "print(\"‚Ä¢ Use --jit-graph for debugging and hierarchy analysis\")\n",
    "print(\"‚Ä¢ Use ONNX export for production deployment\")\n",
    "print(\"‚Ä¢ Use --fx-graph for alternative analysis when supported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. File Structure Overview\n",
    "\n",
    "Let's examine what files were generated by our export:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "export_dir = Path(\"../temp/notebook_exports\")\n",
    "\n",
    "print(\"üìÅ GENERATED FILES OVERVIEW\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if export_dir.exists():\n",
    "    all_files = []\n",
    "    \n",
    "    # Walk through all files\n",
    "    for root, dirs, files in os.walk(export_dir):\n",
    "        for file in files:\n",
    "            file_path = Path(root) / file\n",
    "            relative_path = file_path.relative_to(export_dir)\n",
    "            file_size = file_path.stat().st_size\n",
    "            \n",
    "            all_files.append({\n",
    "                'File': str(relative_path),\n",
    "                'Size': f\"{file_size:,} bytes\",\n",
    "                'Type': file_path.suffix or 'directory'\n",
    "            })\n",
    "    \n",
    "    # Sort by file type and name\n",
    "    all_files.sort(key=lambda x: (x['Type'], x['File']))\n",
    "    \n",
    "    # Display file structure\n",
    "    df_files = pd.DataFrame(all_files)\n",
    "    print(df_files.to_string(index=False))\n",
    "    \n",
    "    # File type distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    type_counts = df_files['Type'].value_counts()\n",
    "    plt.pie(type_counts.values, labels=type_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "    plt.title('Generated File Types')\n",
    "    \n",
    "    # File sizes\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sizes = [int(size.split()[0].replace(',', '')) for size in df_files['Size']]\n",
    "    file_names = [f.split('/')[-1][:15] + '...' if len(f.split('/')[-1]) > 15 else f.split('/')[-1] for f in df_files['File']]\n",
    "    \n",
    "    plt.bar(range(len(sizes)), sizes, alpha=0.7)\n",
    "    plt.xlabel('Files')\n",
    "    plt.ylabel('Size (bytes)')\n",
    "    plt.title('File Sizes')\n",
    "    plt.xticks(range(len(file_names)), file_names, rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nüìä Summary: {len(all_files)} files generated\")\n",
    "    total_size = sum(int(size.split()[0].replace(',', '')) for size in df_files['Size'])\n",
    "    print(f\"üì¶ Total size: {total_size:,} bytes ({total_size/1024:.1f} KB)\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Export directory not found\")\n",
    "\n",
    "print(\"\\nüéâ NOTEBOOK ANALYSIS COMPLETE!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"‚Ä¢ Explore individual JSON files for detailed analysis\")\n",
    "print(\"‚Ä¢ Use the generated .py files to understand graph structure\")\n",
    "print(\"‚Ä¢ Compare ONNX model with original PyTorch model performance\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}