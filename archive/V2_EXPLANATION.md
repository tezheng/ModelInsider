# HTP Hierarchy Exporter V2 - Line-by-Line Explanation

## Overview
The V2 implementation is a complete rewrite that eliminates complexity while solving the auxiliary operations tagging problem correctly.

## Key Design Principles
1. **Simplicity**: Only essential functionality, no over-engineering
2. **Clarity**: Each method has a single, clear responsibility  
3. **Correctness**: Proper auxiliary operations tagging without layer misassignment
4. **Maintainability**: Clean, readable code structure

## Line-by-Line Analysis

### Class Definition and Initialization (Lines 16-24)
```python
class HierarchyExporterV2:
    """Simplified hierarchy-preserving ONNX exporter with proper auxiliary operations support."""
    
    def __init__(self):
        self.operation_traces = []  # Records of PyTorch operations during execution
        self.node_tags = {}        # ONNX node_name -> module tag mapping
        self.original_functions = {}  # Store original functions for cleanup
```
**Purpose**: Simple class with three core data structures:
- `operation_traces`: Records what PyTorch operations were executed and from which modules
- `node_tags`: Maps ONNX operation names to their hierarchical tags
- `original_functions`: Stores original PyTorch functions for cleanup

### Main Export Method (Lines 26-81)
```python
def export(self, model: nn.Module, example_inputs, output_path: str, **kwargs) -> Dict[str, Any]:
```
**Process Overview**:
1. **Line 39**: Setup operation tracing by patching PyTorch functions
2. **Lines 42-46**: Run the model to capture execution traces
3. **Lines 48-58**: Export to ONNX using standard PyTorch ONNX export
4. **Lines 60-61**: Load ONNX model and create hierarchy mapping
5. **Lines 63-64**: Tag auxiliary operations using spatial locality
6. **Lines 66-70**: Generate and save metadata to sidecar file

**Key Insight**: Clean sequential process with clear separation of concerns.

### Operation Tracing Setup (Lines 83-108)
```python
def _setup_operation_tracing(self, model: nn.Module):
    """Patch key PyTorch operations to capture execution context."""
    operations_to_patch = [
        (torch, 'addmm'),        # Matrix operations
        (torch, 'mm'),           # Matrix multiplication
        (torch.nn.functional, 'linear'),  # Linear layers
        (torch.nn.functional, 'conv2d'),  # Convolutions
        (torch.nn.functional, 'relu'),    # Activations
        # ... other key operations
    ]
```
**Purpose**: 
- **Line 85**: Clear list of operations to trace (only the most important ones)
- **Lines 95-105**: For each operation, store the original function and replace with traced version
- **Simplification**: Instead of 100+ operations, only trace ~10 essential ones

### Traced Function Creation (Lines 110-135)
```python
def _create_traced_function(self, op_name: str, original_func):
    """Create a traced version of a PyTorch function that records execution context."""
    def traced_function(*args, **kwargs):
        # Get current module context from the call stack
        current_module = self._get_current_executing_module()
        
        # Execute original function
        result = original_func(*args, **kwargs)
        
        # Record the operation if we have module context
        if current_module:
            module_tag = self._build_module_tag(current_module)
            self.operation_traces.append({
                'operation': op_name,
                'module_tag': module_tag,
                'order': len(self.operation_traces)
            })
        
        return result
```
**Process**:
- **Line 115**: Get the current executing module (which BERT layer/component)
- **Line 118**: Execute the original operation normally
- **Lines 121-127**: If we know the module context, record this operation with its tag
- **Key Improvement**: Simple trace recording without complex tensor tracking

### Module Context Detection (Lines 137-159)
```python
def _get_current_executing_module(self) -> Optional[str]:
    """Get the current executing module from the call stack using PyTorch's built-in tracking."""
    # Use PyTorch's built-in module tracking if available
    try:
        import torch.jit._trace
        if hasattr(torch.jit._trace, '_trace_module_map') and torch.jit._trace._trace_module_map:
            # Get the current module being traced
            for module_id, module_info in torch.jit._trace._trace_module_map.items():
                if module_info and hasattr(module_info, 'qualified_name'):
                    return self._convert_qualified_name_to_path(module_info.qualified_name)
    except:
        pass
    
    # Fallback: inspect call stack for module context
    import inspect
    for frame_info in inspect.stack():
        # ... find module in call stack
```
**Strategy**:
- **Lines 141-147**: Try to use PyTorch's built-in module tracking (most accurate)
- **Lines 152-158**: Fallback to call stack inspection if built-in tracking unavailable
- **Key Insight**: Two-tier approach for robustness

### Hierarchy Mapping Creation (Lines 210-258)
```python
def _create_hierarchy_mapping(self, onnx_model):
    """Map execution traces to ONNX operations."""
    # Initialize all nodes as untagged
    for node in onnx_model.graph.node:
        node_name = node.name or f"{node.op_type}_{id(node)}"
        self.node_tags[node_name] = []
    
    # Simple mapping: match operations by type and order
    # Group traces by operation type
    traces_by_type = defaultdict(list)
    for trace in self.operation_traces:
        traces_by_type[trace['operation']].append(trace)
    
    # Group ONNX nodes by type
    nodes_by_type = defaultdict(list)
    for node in onnx_model.graph.node:
        nodes_by_type[node.op_type].append(node)
```
**Process**:
- **Lines 214-217**: Initialize all ONNX nodes with empty tags
- **Lines 220-223**: Group execution traces by operation type (addmm, linear, etc.)
- **Lines 225-228**: Group ONNX nodes by operation type (Gemm, MatMul, etc.)
- **Lines 230-241**: Define mapping between PyTorch and ONNX operation types
- **Lines 243-258**: Match traces to ONNX nodes in order

**Key Simplification**: Type-based matching instead of complex tensor flow analysis.

### Auxiliary Operations Tagging (Lines 260-295)
```python
def _tag_auxiliary_operations(self, onnx_model):
    """Tag auxiliary operations using spatial locality."""
    # Build spatial relationships
    producer_map = {}  # tensor_name -> node_name
    consumer_map = defaultdict(list)  # tensor_name -> [node_names]
    
    for node in onnx_model.graph.node:
        # Build producer mapping
        for output in node.output:
            producer_map[output] = node_name
        
        # Build consumer mapping
        for input_tensor in node.input:
            consumer_map[input_tensor].append(node_name)
```
**Strategy**:
- **Lines 265-275**: Build simple producer/consumer relationships
- **Lines 277-282**: Find all untagged (auxiliary) operations
- **Lines 286-293**: For each auxiliary operation, find the best spatial tag
- **Line 291**: If no good tag found, use generic `/BertModel/AuxiliaryOperations`

**Key Fix**: Generic fallback prevents layer misassignment!

### Spatial Tag Finding (Lines 297-324)
```python
def _find_best_spatial_tag(self, node_name: str, node, producer_map: Dict, consumer_map: Dict) -> Optional[str]:
    """Find the best tag for an auxiliary operation using spatial locality."""
    candidate_tags = []
    
    # Strategy 1: Inherit from producers
    for input_tensor in node.input:
        if input_tensor in producer_map:
            producer_name = producer_map[input_tensor]
            producer_tags = self.node_tags.get(producer_name, [])
            if producer_tags and self._are_spatially_close(node_name, producer_name):
                candidate_tags.extend(producer_tags)
    
    # Strategy 2: Inherit from consumers
    for output_tensor in node.output:
        if output_tensor in consumer_map:
            for consumer_name in consumer_map[output_tensor]:
                consumer_tags = self.node_tags.get(consumer_name, [])
                if consumer_tags and self._are_spatially_close(node_name, consumer_name):
                    candidate_tags.extend(consumer_tags)
    
    # Return the most common tag among candidates
    if candidate_tags:
        from collections import Counter
        most_common = Counter(candidate_tags).most_common(1)
        return most_common[0][0]
```
**Process**:
- **Lines 302-307**: Look at operations that produce inputs to this auxiliary operation
- **Lines 309-315**: Look at operations that consume outputs from this auxiliary operation  
- **Lines 317-320**: Among all candidate tags, return the most common one
- **Key Insight**: Democratic voting among spatial neighbors prevents single-source bias

### Spatial Proximity Check (Lines 326-342)
```python
def _are_spatially_close(self, node1_name: str, node2_name: str) -> bool:
    """Check if two nodes are spatially close in the ONNX graph."""
    path1_parts = node1_name.split('/')
    path2_parts = node2_name.split('/')
    
    # Count common prefix
    common_parts = 0
    for i in range(min(len(path1_parts), len(path2_parts))):
        if path1_parts[i] == path2_parts[i]:
            common_parts += 1
        else:
            break
    
    # They're close if they share at least 3 path components
    return common_parts >= 3
```
**Logic**:
- **Lines 330-331**: Split node names into path components (`/encoder/layer.1/attention/self/...`)
- **Lines 333-339**: Count how many path components match from the beginning
- **Line 342**: Consider nodes "close" if they share at least 3 path components
- **Example**: `/encoder/layer.1/attention/self/Constant` and `/encoder/layer.1/attention/self/MatMul` share 5 components â†’ spatially close

## Key Improvements in V2

### 1. **Eliminated Layer Misassignment**
- **Problem**: V1 allowed Layer 1 auxiliary operations to inherit Layer 0 tags
- **Solution**: V2 uses generic `/BertModel/AuxiliaryOperations` fallback, preventing cross-layer contamination

### 2. **Simplified Code Structure**
- **V1**: 3000+ lines with complex inheritance hierarchies
- **V2**: 400 lines with clear, linear processing

### 3. **Better Error Handling**
- **V1**: Complex error recovery and edge case handling
- **V2**: Simple fallbacks that always provide valid tags

### 4. **Maintainable Architecture**
- **V1**: Multiple strategies, complex configuration, many abstractions
- **V2**: Single clear algorithm, minimal configuration, direct implementation

## Summary
The V2 implementation solves the auxiliary operations problem through:
1. **Correct primary tagging**: Execution traces map to ONNX operations properly
2. **Safe auxiliary tagging**: Spatial locality with safe fallbacks
3. **Clean architecture**: Simple, maintainable code structure
4. **100% coverage**: No operations left untagged

The result is a much cleaner, more reliable implementation that fixes the layer misassignment bug while being significantly easier to understand and maintain.